[{"categories":["Linux Distro"],"content":"自从发现了i3wm之后，就爱上了tiling，尝试了xmonad|awesome|i3wm，然而，孱弱的管理功能（基本没有），导致在笔记本上很难完美舒适的姿势。在这里回顾一下Hopping的各种姿势体验。","date":"2020-06-29","objectID":"/distro-hop/","tags":["DE","Linux","Distro Hopper"],"title":"最近频繁的切换Distro，为了一个最舒服的DE","uri":"/distro-hop/"},{"categories":["Linux Distro"],"content":"为什么会喜欢Tiling window manager呢？个人使用linux作为主要的学习和开发平台（只有一台笔记本，dell xps15 最渣配），平时主要的routine就是虚拟终端+Emacs+Firefox[Chrome]，非常的固定，每次打开应用之后默认的动作都是全屏，然后在各个窗口之间切换。通过tiling，可以省略全屏这一步，同时通过虚拟桌面，直接分离各个应用，完全手不离键盘就可以完成所有的切换，非常效率（帅）。主要是喜欢这种简洁的感觉。 Win + Tab 或者 Alt + Tab 这种非人类的操作基本上我是不用的。还有macOS那种全屏之后左划右划，特别奇怪，还有不计其数的人为了这个去买苹果的触摸板（请原谅我的穷）。 这里简单罗列一下最近试过印象比较好的的Distro+DE的组合，截图什么的，就算了，太麻烦，有兴趣的人，自然会自行闻鸡起舞。 ","date":"2020-06-29","objectID":"/distro-hop/:0:0","tags":["DE","Linux","Distro Hopper"],"title":"最近频繁的切换Distro，为了一个最舒服的DE","uri":"/distro-hop/"},{"categories":["Linux Distro"],"content":"Manjaro i3 我装的是19.x的版本，现在最新的已经20.0.3了好像。 Manjaro i3呢，不是官方的版本，属于社区维护的性质，但它更新的非常快，基本上都是紧密贴合manjaro官方发布的节奏，基本目前不用担心失去维护。 我装的时候，那个版本有个bug，安装程序没有中文支持，这个有点傻。不过不影响安装，一路next到底，重启，一个精心配置过的i3wm(i3gap)，即开即用。整个桌面和电源管理套件，用的是xfce的。我记得一个非常大的缺点是，快捷键没用使用Vim的h,j,k,l。所以要自己修改一下配置。默认自带的conky也配置的很好。 Manjaro i3 ","date":"2020-06-29","objectID":"/distro-hop/:1:0","tags":["DE","Linux","Distro Hopper"],"title":"最近频繁的切换Distro，为了一个最舒服的DE","uri":"/distro-hop/"},{"categories":["Linux Distro"],"content":"Regolith(月岩灰) 非常漂亮，比较小众，我也忘记了我是怎么找到它的。 Regolith是一个基于Ubuntu Gnome的桌面套件，可以说只是把window manager换成了i3gap，其他都是Gnome的。所以你在gnome里的所有功能和交互，在regolith里都基本保留。Gnome的桌面我一直觉得非常反人类，一直不能get到它这么设计的点，甚至一些基本配置都需要安装Tweak和dconf才能完成，不厌其烦。这点regolith也爱莫能助。 Regolith的作者对i3做了很多细心的配置，super + ?会弹出一个Help窗口介绍所有的快捷键，这一点我最喜欢。 相比Manjaro i3，regolith感觉要更精致一些，因为主题配色和gnome套件加成的关系。 Regolith ","date":"2020-06-29","objectID":"/distro-hop/:2:0","tags":["DE","Linux","Distro Hopper"],"title":"最近频繁的切换Distro，为了一个最舒服的DE","uri":"/distro-hop/"},{"categories":["Linux Distro"],"content":"Manjaro KDE with Krohnkite(极力推荐) KDE当然不是什么tiling wm啦，但是KDE的功能之强，配置之具，一直可以不断的震惊到我。 最近碰巧在油管上看到了一个关于Krohnkite的介绍，怦然心动。 Krohnkite是KDE的默认WM KWin的一个脚本，通过Krohnkite，可以直接把KWin变成一个tiling window manager，还可以自定义gap，神不神奇？我装了之后，非常惊艳，可谓是极其完美的。拥有了KDE所有的管理配置能力，同时还有完美的Tiling。只要配置一下虚拟桌面和对应的快捷键，整个DE的操作体验可以完美复刻i3。公司的小朋友看到我的自定之后，也依然决然的装上了，现在沉浸不能自拔。 Krohnkite Github ","date":"2020-06-29","objectID":"/distro-hop/:3:0","tags":["DE","Linux","Distro Hopper"],"title":"最近频繁的切换Distro，为了一个最舒服的DE","uri":"/distro-hop/"},{"categories":["Linux Distro"],"content":"LinuxMint Cinnamon 这个是我目前在用的，虽然不能说是tiling，但是Cinnamon自带的windows tiling snap功能，还是能比较好的为我提供“类tiling”的体验。 从Krohnkite换到Cinnamon其实我是挺不情愿的，因为Krohnkite真的挺完美的。但是KDE本身有点让我头疼的是，xps15的屏是普通DPI的，我办公室一直用的4K的27寸显示器。不能在这两者之间设置不同的DPI scale我不怪KDE，X11和Wayland都各种残疾。但是，我只使用单显示器，切换DPI每次都要重启这个就很烦了。而且莫名的，HDMI不能60hz，只能50hz。 所以我现在在LinuxMint Cinnamon下，用Roif+Albert+Cinnamon自带的功能，基本上也可以符合自己的使用习惯了。 流水帐完成","date":"2020-06-29","objectID":"/distro-hop/:4:0","tags":["DE","Linux","Distro Hopper"],"title":"最近频繁的切换Distro，为了一个最舒服的DE","uri":"/distro-hop/"},{"categories":["Emacs"],"content":"一直苦于没有中文输入法，在Emacs和VSCode之间来回切换，两种不同的键位mindset确实累，经常敲错。","date":"2020-06-29","objectID":"/emacs-im/","tags":["emacs"],"title":"终于可以在Emacs下调用Fcitx打拼音了","uri":"/emacs-im/"},{"categories":["Emacs"],"content":"LC_CTYPE=zh_CN.UTF-8 emacs 据说这是一个Emacs的千年bug。 这就是这篇Blog的全部内容了。。。。。。之前在Manjaro KDE下，这个是无效的，不知道为什么，而且我在Settings里只要装了中文支持，命令行就会变成中文的，.pam_environment怎么修改都没有用，而且Emacs还是不能输入中文。。。。。。这就很Fuck了，给我看中文，但是不给我输入中文的福利。 最近Linux Mint 20发布了，重新装了Cinnamon，一切都OK了。 为了不影响系统其他部分的显示，拷贝/usr/share/applications/emacs.desktop到$HOME/.local/share/applications/下，然后修改Exec=env LC_CTYPE=zh_CN.UTF-8 emacs %F。 大功告成。 ","date":"2020-06-29","objectID":"/emacs-im/:1:0","tags":["emacs"],"title":"终于可以在Emacs下调用Fcitx打拼音了","uri":"/emacs-im/"},{"categories":null,"content":"全新的429Cubic inch(换算排气量为7000c.c.)的V8引擎，Boss429 Mustang也仅在1969年(859辆)及1970年(499辆)间共产下了1358辆。1969 Ford Mustang Boss 429 \" 全新的429Cubic inch(换算排气量为7000c.c.)的V8引擎，Boss429 Mustang也仅在1969年(859辆)及1970年(499辆)间共产下了1358辆。 ","date":"2020-06-10","objectID":"/about/:0:0","tags":null,"title":"关于","uri":"/about/"},{"categories":["golang源码阅读"],"content":"之前已经读过了\"new三剑客\"。尤其是其中的channel，既然看过了channel，那么select这个结构，是不可能放过的。平时写业务代码的时候，select用的熟不熟，可以看得出是不是一个老狗\u003ci class=\"fa fa-dog\"\u003e\u003c/i\u003e。","date":"2020-06-08","objectID":"/go-select/","tags":["golang","runtime","select","源码阅读"],"title":"Golang Select源码阅读笔记","uri":"/go-select/"},{"categories":["golang源码阅读"],"content":"之前已经读过了\"new三剑客”。尤其是其中的channel，既然看过了channel，那么select这个结构，是不可能放过的。平时写业务代码的时候，select用的熟不熟，可以看得出是不是一个老狗。 唉，这select的阅读不可能不涉及到goroutine的部分，不过好在在channel的代码里我们已经看过一大部分了。race detector的部分都略过。 面试的时候很多面试官问的一个高频问题就是select的分支执行是顺序的还是随机的？ ","date":"2020-06-08","objectID":"/go-select/:0:0","tags":["golang","runtime","select","源码阅读"],"title":"Golang Select源码阅读笔记","uri":"/go-select/"},{"categories":["golang源码阅读"],"content":"主要的常量和类型定义 吐嘈一下，go的常量定义真的是丑。 // scase.kind values. // Known to compiler. // Changes here must also be made in src/cmd/compile/internal/gc/select.go's walkselectcases. const ( caseNil = iota caseRecv caseSend caseDefault ) // Select case descriptor. // Known to compiler. // Changes here must also be made in src/cmd/internal/gc/select.go's scasetype. type scase struct { c *hchan // chan elem unsafe.Pointer // data element kind uint16 pc uintptr // race pc (for race detector / msan) releasetime int64 } 首先是定义了4个scase.kind常量，表示select分支(case)的类型。结合我们平时写go的经验，select里面的case就4个类型，顾名思义。然后是scase，编译器用来描述一个case用的struct。字段不多，scase.c用来保存我们在case里阻塞的读写channel。kind对应之前的常量。releasetime暂时不知道是干嘛的。 温故知新的超链接Go Chan ","date":"2020-06-08","objectID":"/go-select/:1:0","tags":["golang","runtime","select","源码阅读"],"title":"Golang Select源码阅读笔记","uri":"/go-select/"},{"categories":["golang源码阅读"],"content":"select 的主体 整个select 结构只对应一个函数：func selectgo(cas0 *scase, order0 *uint16, ncases int) (int, bool)。所以我们就把整个代码打碎，在代码中直接以注释的形式来阅读吧，不再整段代码copy了。 先看注释，源码可以不看，注释一定要看。 // selectgo implements the select statement. // // cas0 points to an array of type [ncases]scase, and order0 points to // an array of type [2*ncases]uint16 where ncases must be \u003c= 65536. // Both reside on the goroutine's stack (regardless of any escaping in // selectgo). // cas0 是一个指向[ncases]scase数组类型的指针， order0是一个指向[2*ncases]uint16类型数组的指针，其中ncases必须小于等于65535，很明显uint16不能溢出，所以一个select里面只有最多65535个case，写那么多case，会被fired吧。 // 这两个变量都分配在goroutine的栈上（无视selectgo中的任何逃逸）（这句话我也不太理解，功夫还不够）。 // selectgo returns the index of the chosen scase, which matches the // ordinal position of its respective select{recv,send,default} call. // Also, if the chosen scase was a receive operation, it reports whether // a value was received. // selectgo 返回的是选中的scase的索引，该索引是按照select中的case语句申明的先后顺序。而且，如果选中的scase是一个receive操作，selectgo还会返回是否有值已经被接收了。 ","date":"2020-06-08","objectID":"/go-select/:2:0","tags":["golang","runtime","select","源码阅读"],"title":"Golang Select源码阅读笔记","uri":"/go-select/"},{"categories":["golang源码阅读"],"content":"准备工作 编译器把所有的case语句转换成scase数组之后，传给selectgo，selectgo干的第一件事情，是重组两个排序：一个加锁排序和一个轮寻排序。 // NOTE: In order to maintain a lean stack size, the number of scases // is capped at 65536. // cas1和cas0没有啥区别，直接通过unsafe转换成一个数组的指针，方便下标访问。 cas1 := (*[1 \u003c\u003c 16]scase)(unsafe.Pointer(cas0)) // order1是一个2×ncases大小的数组，里面会存放两组cas1的下标队列。 order1 := (*[1 \u003c\u003c 17]uint16)(unsafe.Pointer(order0)) // 保持一个slice指向cas1 scases := cas1[:ncases:ncases] // 这里是划分order1的空间，前半部分给轮寻排序，后半部分给加锁排序，两者的长度都是ncases。 pollorder := order1[:ncases:ncases] lockorder := order1[ncases:][:ncases:ncases] // Replace send/receive cases involving nil channels with // caseNil so logic below can assume non-nil channel. // 先过滤channel为nil的cases，caseDefault是一个特例，要保留它。 for i := range scases { cas := \u0026scases[i] if cas.c == nil \u0026\u0026 cas.kind != caseDefault { *cas = scase{} } } // 大概是profile相关的 var t0 int64 if blockprofilerate \u003e 0 { t0 = cputicks() for i := 0; i \u003c ncases; i++ { scases[i].releasetime = -1 } } // The compiler rewrites selects that statically have // only 0 or 1 cases plus default into simpler constructs. // The only way we can end up with such small sel.ncase // values here is for a larger select in which most channels // have been nilled out. The general code handles those // cases correctly, and they are rare enough not to bother // optimizing (and needing to test). // 编译器会把那些只有0或者1个case外加default case的select都重写成更加简单的结构。 // 我们在这里会遇到sel.ncases非常非常小的唯一的情况是，在一个case比较多的select中，大部分分支的 // chan都因为nil被排除掉了。但是我们的代码已经很好的兼容这种情况，而且这种情况本身也是足够罕见到不值得专门去优化。 // generate permuted order // 在[]pollorder里填充随机化的轮寻的排序。 // pollorder本来是[0, 1, 2, 3, ..... ncases-1] // 然后fastrandn用来打乱这个排序。这个可以回答面试官的问题吧。 for i := 1; i \u003c ncases; i++ { // 在[0, i+1)区间内快速获得一个随机整数j。 j := fastrandn(uint32(i + 1)) // 把pollorder[j]移到pollorder[i]，就等于在pollorder中空出了随机位置j。 pollorder[i] = pollorder[j] // 然后把第i个case的索引i，放入pollorder。因为pollorder在进入for之前，保持的是全部的顺序序列， // 所以这里可以的uint16(i)就是原本pollorder[i]的值。 // 整个逻辑就变成了遍历整个数组，每次循环都把当前值和之前的某一个随机位置的值交换位置。这样就完成了pollorder的随机化。 pollorder[j] = uint16(i) } // 接下来，要排lockorder的序，lockorder的排序是有要求的，不像pollorder可以随机乱序。 // sort the cases by Hchan address to get the locking order. // simple heap sort, to guarantee n log n time and constant stack footprint. // 这里是采用堆排序，nlog n，来按照scase所包含的Hchan字段值的地址来生成加锁的顺序。 // 根据后面的代码以及加解锁的逻辑，按照hchan的地址排序是因为chan可能出现两次，这样比较容易找到出现两次的chan，只加解锁一次。 // lockorder里生成了一个最大堆 for i := 0; i \u003c ncases; i++ { j := i // Start with the pollorder to permute cases on the same channel. // 这里是根据已经被随机排列过的pollorder来遍历所有的cases // c保持一个当前case的游标 c := scases[pollorder[i]].c // (j-1)/2是j的父节点，如果j的父节点排序高于c的排序，那么就认为，j的其他祖先的排序也都高于c的排序, for j \u003e 0 \u0026\u0026 scases[lockorder[(j-1)/2]].c.sortkey() \u003c c.sortkey() { // j \u003e 0只是一个保护。 // k指向j的父节点。 // 如果c的父节点的排序低于c的排序，那么就把c的父节点降到c的位置 k := (j - 1) / 2 lockorder[j] = lockorder[k] // 把j指到被调整的父节点的位置，进入下一个循环，从新的j开始继续检查父节点的排序。 j = k } // 直到j的排序满足j的排序小于j的父节点，把pollorder[i]放入lockorder[j]。 // 因为这里的外循环是从0开始的，所以i在每一个位置上，内循环都可以保证看到一个c的排序小于自己父节点的排序， // 就可以认为c的所有的祖先节点的排序都比祖先的父节点要小。 // 这里j指向的应该是最后一个被移动过的节点，也就是当前pollorder[i]应该存在的节点位置。 lockorder[j] = pollorder[i] } // 对lockorder进行堆排序 for i := ncases - 1; i \u003e= 0; i-- { // 在[0, i]这个区间 // 暂时保存当前游标访问的lockorder中的元素，也就是区间的末尾（将会被沉底的堆顶覆盖）。 o := lockorder[i] // c始终都是lockorder当前循环访问的元素所指向的scase所包含的hchan c := scases[o].c // 把堆定元素放到当前区间的末尾，堆顶即待排序元素的最大值，让最大值沉底。 lockorder[i] = lockorder[0] // j指向堆顶，再进行一个最大堆的构造 j := 0 for { // k是左子节点，k+1是右子节点 k := j*2 + 1 if k \u003e= i { // break内循环 break } if k+1 \u003c i \u0026\u0026 scases[lockorder[k]].c.sortkey() \u003c scases[lockorder[k+1]].c.sortkey() { // 如果k+1\u003ci，并且左子节点的排序小于右子节点的排序，k++ // 为了让k取子节点中排序较大的那个。 k++ } // 因为这个已经是最大堆，所以堆顶空出来之后 // 要做的事情就是把两个子节点中交大的那个和c做比较 // 如果c大，那么直接用c作为新的堆顶，一切就都恢复到了最大堆，可以进行下一个沉底动作了。 if c.sortkey() \u003c scases[lockorder[k]].c.sortkey() { // 如果c小，那么把较大的字节点移动到堆顶 lockorder[j] = lockorder[k] // 进入被移走堆顶的子堆 j = k // continue，继续在被移走堆顶的子堆里面做相同的动作 continue } break } // 这里的j就指向了，这个区间[0, i]原本的末尾元素，在堆顶沉底之后应该在的位置，从而继续保持最大堆，进入下一个循环。 lockorder[j] = o } // 到此，我们就拥有了两个不同的scase的排序队列：lockorder和pollorder。他们会在各自的战场发光发热。 ","date":"2020-06-08","objectID":"/go-select/:2:1","tags":["golang","runtime","select","源码阅读"],"title":"Golang Select源码阅读笔记","uri":"/go-select/"},{"categories":["golang源码阅读"],"content":"加锁解锁 func sellock(scases []scase, lockorder []uint16) { var c *hchan for _, o := range lockorder { c0 := scases[o].c // lockorder是根据scase.c的地址进行排序的， // 如果case中有两个case分别对同一个chan进行send/recv // 这两个case在排序后会排在一起，这个时候，我们只能在chan第一次出现的时候加锁并跳过第二次出现。 // 在解锁的时候重复这个动作。 if c0 != nil \u0026\u0026 c0 != c { c = c0 lock(\u0026c.lock) } } } func selunlock(scases []scase, lockorder []uint16) { // We must be very careful here to not touch sel after we have unlocked // the last lock, because sel can be freed right after the last unlock. // Consider the following situation. // First M calls runtime·park() in runtime·selectgo() passing the sel. // Once runtime·park() has unlocked the last lock, another M makes // the G that calls select runnable again and schedules it for execution. // When the G runs on another M, it locks all the locks and frees sel. // Now if the first M touches sel, it will access freed memory. // 这段不是很明白，可能要等看过GPM调度之后才会明白。 // 这里我们必须十分小心，在我们释放了最后一个锁以后，就不能再触碰sel。 // 因为sel有可能在我们释放最后一个锁之后立马也被释放了。 // 设想如下场景 // 当第一个M在runtime.selectgo()里面调用runtime.park()，并传入sel。 // 一旦runtime.park()释放了最后一个锁，立马有另一个M标记刚才调用select的G为可运行状态并调度G来执行。 // 当那个G运行在了另一个M上的时候，G会给所有的锁上锁，并释放掉sel。 // 那么这个时候如果第一个M访问到了sel，它将会访问到已经释放的内存。 // 顺序加锁，倒序解锁 for i := len(scases) - 1; i \u003e= 0; i-- { c := scases[lockorder[i]].c if c == nil { break } // 因为倒序，所以在重复chan出现的时候，在第二次解锁。 if i \u003e 0 \u0026\u0026 c == scases[lockorder[i-1]].c { continue // will unlock it on the next iteration } unlock(\u0026c.lock) } } ","date":"2020-06-08","objectID":"/go-select/:2:2","tags":["golang","runtime","select","源码阅读"],"title":"Golang Select源码阅读笔记","uri":"/go-select/"},{"categories":["golang源码阅读"],"content":"是时候开始真正的表演了 一大段代码，在go里面这么密集的使用goto真的好吗？不过，大神们留下的代码，还是很值得细品，你品，你慢慢品。 // 一堆变量，后面会有用的吧。 var ( gp *g sg *sudog c *hchan k *scase sglist *sudog sgnext *sudog qp unsafe.Pointer nextp **sudog ) loop: // pass 1 - look for something already waiting // 第一步，试图找到已经就绪的case var dfli int var dfl *scase // scase的数组下标 var casi int // scase的指针，casi对应的scase var cas *scase var recvOK bool for i := 0; i \u003c ncases; i++ { // 这里可以看到所有的scases的遍历都是根据pollorder里的排序。 casi = int(pollorder[i]) cas = \u0026scases[casi] // 获得当前的scase的chan c = cas.c switch cas.kind { case caseNil: // 直接pass掉不包含send/receive的case continue case caseRecv: // 如果当前是一个recv操作 // 就从当前case的chan的发送等待队列中，尝试出队一个sudog sg = c.sendq.dequeue() // 如果chan当前有阻塞的send，那么就从send等待队列获得一个sudog，那么直接跳到recv if sg != nil { goto recv } // 如果没有sudog，检查chan的qcount，判断是否是带缓冲的chan，直接到bufrecv if c.qcount \u003e 0 { goto bufrecv } // 如果chan已经被关闭，recv的操作可以立即返回，直接到rclose if c.closed != 0 { goto rclose } // 都没有满足，那么这个recv操作继续阻塞 case caseSend: // 如果当前是一个send操作 if raceenabled { racereadpc(c.raceaddr(), cas.pc, chansendpc) } // 如果chan被关闭了，对一个关闭的chan写是会panic的，直接到sclose if c.closed != 0 { goto sclose } // 如果chan当前有阻塞的read，那么尝试从chan的读取等待队列出队一个sudog sg = c.recvq.dequeue() // 如果获得了一个sudog，直接跳到send if sg != nil { goto send } // 如果是带缓冲的chan并且缓冲还没有填满，直接到bufsend if c.qcount \u003c c.dataqsiz { goto bufsend } case caseDefault: // mark default case dfli = casi dfl = cas } } // 如果default case存在，并且当前没有其他的send/recv就绪，那么select的执行就掉到default上。 if dfl != nil { // 解锁 selunlock(scases, lockorder) casi = dfli cas = dfl // 跳到retc，这个时候没有recv执行，所以recvOK = false goto retc } // 没有recv/send就绪，也没有defaultcase // 就要第二次遍历scases，把所有的case对应的hchan都处理掉。 // pass 2 - enqueue on all chans // 获得当前的goroutine指针gp gp = getg() if gp.waiting != nil { throw(\"gp.waiting != nil\") } nextp = \u0026gp.waiting for _, casei := range lockorder { casi = int(casei) cas = \u0026scases[casi] // 跳过不是send/recv的case if cas.kind == caseNil { continue } c = cas.c // 获得一个sudog，一个当前goroutine在阻塞等待队列的代理。 sg := acquireSudog() // 代理gp sg.g = gp // mark当前等待是在select sg.isSelect = true // No stack splits between assigning elem and enqueuing // sg on gp.waiting where copystack can find it. sg.elem = cas.elem sg.releasetime = 0 if t0 != 0 { sg.releasetime = -1 } sg.c = c // Construct waiting list in lock order. // 用nextp把所有的sudog构建成一个list *nextp = sg nextp = \u0026sg.waitlink // 根据send/recv塞进相应的等待队列 switch cas.kind { case caseRecv: c.recvq.enqueue(sg) case caseSend: c.sendq.enqueue(sg) } } // gopark让goroutine让出执行，等待被别的goroutine唤醒 // wait for someone to wake us up gp.param = nil gopark(selparkcommit, nil, waitReasonSelect, traceEvGoBlockSelect, 1) gp.activeStackChans = false // 加锁，在我们被唤醒之后，hchans不能再有变化。 sellock(scases, lockorder) gp.selectDone = 0 // 重建唤醒我们的sudog sg = (*sudog)(gp.param) gp.param = nil // 这里一定有至少一个chan发生就绪 // pass 3 - dequeue from unsuccessful chans // otherwise they stack up on quiet channels // record the successful case, if any. // We singly-linked up the SudoGs in lock order. casi = -1 cas = nil // 从gp.waiting里拿到之前构造的sudog的list sglist = gp.waiting // Clear all elem before unlinking from gp.waiting. // 把等待的sudog的单向链表做一些整理操作，关联的chan和元素都置为nil for sg1 := gp.waiting; sg1 != nil; sg1 = sg1.waitlink { sg1.isSelect = false sg1.elem = nil sg1.c = nil } gp.waiting = nil // 按照lockorder的顺序遍历，我们在构造sudog waiting list的时候，也是按照lockorder的顺序构造的。 // 所以我们这里可以按sudog waiting list的顺序，获得scase。 for _, casei := range lockorder { k = \u0026scases[casei] if k.kind == caseNil { continue } if sglist.releasetime \u003e 0 { k.releasetime = sglist.releasetime } // sg 就是唤醒我们的sudog，这时与之对应的scase和下标分别就是k和casei。 if sg == sglist { // sg has already been dequeued by the G that woke us up. casi = int(casei) cas = k } else { // 简单的把sglist指向的sudog从hchan的阻塞队列里移除。 c = k.c if k.kind == caseSend { c.sendq.dequeueSudoG(sglist) } else { c.recvq.dequeueSudoG(sglist) } } // 释放sglist指向的sudog，把sglist指向列表的下一个元素 sgnext = sglist.waitlink sglist.waitlink = nil releaseSudog(sglist) sglist = sgnext } // 这里主要是代码重用，当select中的chan因为关闭，而把我们唤醒了，这个时候cas就会等于nil， // 这时代码跳到loop，就足以","date":"2020-06-08","objectID":"/go-select/:2:3","tags":["golang","runtime","select","源码阅读"],"title":"Golang Select源码阅读笔记","uri":"/go-select/"},{"categories":["golang源码阅读"],"content":"我自己也是醉了。Golang的“make三剑客”，Map,Chan,Slice，居然把最简单的slice放到最后来读了。哈哈。无所谓，反正也没人看。曾经我有一次被面试官问到，“slice在高并发情况下会有bug你知道吗？”，但他也没有告诉我是什么bug。看看能不能自己看出个未来。(我当时的回答是，如果真有，那go可以去死了。)","date":"2020-05-29","objectID":"/go-slice/","tags":["golang","runtime","slice","源码阅读"],"title":"Golang Slice源码阅读笔记","uri":"/go-slice/"},{"categories":["golang源码阅读"],"content":"我自己也是醉了。Golang的“make三剑客”，Map,Chan,Slice，居然把最简单的slice放到最后来读了。哈哈。无所谓，反正也没人看。曾经我有一次被面试官问到，“slice在高并发情况下会有bug你知道吗？”，但他也没有告诉我是什么bug。看看能不能自己看出个未来。(我当时的回答是，如果真有，那go可以去死了。) ","date":"2020-05-29","objectID":"/go-slice/:0:0","tags":["golang","runtime","slice","源码阅读"],"title":"Golang Slice源码阅读笔记","uri":"/go-slice/"},{"categories":["golang源码阅读"],"content":"slice定义 type slice struct { array unsafe.Pointer len int cap int } // A notInHeapSlice is a slice backed by go:notinheap memory. type notInHeapSlice struct { array *notInHeap len int cap int } slice的定义显然是非常简单的，我记得这种形式被称为“胖指针”。我有一个pointer指向在内存某个地方的数据，行指针之能。但是我同时还有一些辅助字段来约束或者辅助我对指针指向的数据的操作。但是从外部看来，我就只是一个*slice，那些辅助的字段都不需要让外部知道。 len 就是当前slice可以访问到的长度，超出这个len的都是越界。 cap 就是背后支持这个slice的array的长度，这是真实有效的内存空间的长度。执行append的时候，如果超过了这个cap，将会触发扩容。 len \u003c= cap ","date":"2020-05-29","objectID":"/go-slice/:1:0","tags":["golang","runtime","slice","源码阅读"],"title":"Golang Slice源码阅读笔记","uri":"/go-slice/"},{"categories":["golang源码阅读"],"content":"创建slice 创建slice是有makeslice(et *_type, len, cap int) unsafe.Pointer来实现的。很简单直观，先检查一下要求的大小会不会内存溢出，这里还很细心的区分了如果溢出是因为len还是因为cap。没有问题就直接把要求的内存空间直接分配了。这些mallocgc什么的，我以后再慢慢看。不影响。 func makeslice(et *_type, len, cap int) unsafe.Pointer { mem, overflow := math.MulUintptr(et.size, uintptr(cap)) if overflow || mem \u003e maxAlloc || len \u003c 0 || len \u003e cap { // NOTE: Produce a 'len out of range' error instead of a // 'cap out of range' error when someone does make([]T, bignumber). // 'cap out of range' is true too, but since the cap is only being // supplied implicitly, saying len is clearer. // See golang.org/issue/4085. mem, overflow := math.MulUintptr(et.size, uintptr(len)) if overflow || mem \u003e maxAlloc || len \u003c 0 { panicmakeslicelen() } panicmakeslicecap() } return mallocgc(mem, et, true) } func makeslice64(et *_type, len64, cap64 int64) unsafe.Pointer { len := int(len64) if int64(len) != len64 { panicmakeslicelen() } cap := int(cap64) if int64(cap) != cap64 { panicmakeslicecap() } return makeslice(et, len, cap) } ","date":"2020-05-29","objectID":"/go-slice/:2:0","tags":["golang","runtime","slice","源码阅读"],"title":"Golang Slice源码阅读笔记","uri":"/go-slice/"},{"categories":["golang源码阅读"],"content":"slice扩容 slice的代码量和map是简直不能比的，主要的逻辑就是一个growslice。 // growslice handles slice growth during append. // It is passed the slice element type, the old slice, and the desired new minimum capacity, // and it returns a new slice with at least that capacity, with the old data // copied into it. // The new slice's length is set to the old slice's length, // NOT to the new requested capacity. // This is for codegen convenience. The old slice's length is used immediately // to calculate where to write new values during an append. // TODO: When the old backend is gone, reconsider this decision. // The SSA backend might prefer the new length or to return only ptr/cap and save stack space. func growslice(et *_type, old slice, cap int) slice { if raceenabled { callerpc := getcallerpc() racereadrangepc(old.array, uintptr(old.len*int(et.size)), callerpc, funcPC(growslice)) } if msanenabled { msanread(old.array, uintptr(old.len*int(et.size))) } if cap \u003c old.cap { panic(errorString(\"growslice: cap out of range\")) } if et.size == 0 { // append should not create a slice with nil pointer but non-zero len. // We assume that append doesn't need to preserve old.array in this case. return slice{unsafe.Pointer(\u0026zerobase), old.len, cap} } newcap := old.cap doublecap := newcap + newcap if cap \u003e doublecap { newcap = cap } else { if old.len \u003c 1024 { newcap = doublecap } else { // Check 0 \u003c newcap to detect overflow // and prevent an infinite loop. for 0 \u003c newcap \u0026\u0026 newcap \u003c cap { newcap += newcap / 4 } // Set newcap to the requested cap when // the newcap calculation overflowed. if newcap \u003c= 0 { newcap = cap } } } var overflow bool var lenmem, newlenmem, capmem uintptr // Specialize for common values of et.size. // For 1 we don't need any division/multiplication. // For sys.PtrSize, compiler will optimize division/multiplication into a shift by a constant. // For powers of 2, use a variable shift. switch { case et.size == 1: lenmem = uintptr(old.len) newlenmem = uintptr(cap) capmem = roundupsize(uintptr(newcap)) overflow = uintptr(newcap) \u003e maxAlloc newcap = int(capmem) case et.size == sys.PtrSize: lenmem = uintptr(old.len) * sys.PtrSize newlenmem = uintptr(cap) * sys.PtrSize capmem = roundupsize(uintptr(newcap) * sys.PtrSize) overflow = uintptr(newcap) \u003e maxAlloc/sys.PtrSize newcap = int(capmem / sys.PtrSize) case isPowerOfTwo(et.size): var shift uintptr if sys.PtrSize == 8 { // Mask shift for better code generation. shift = uintptr(sys.Ctz64(uint64(et.size))) \u0026 63 } else { shift = uintptr(sys.Ctz32(uint32(et.size))) \u0026 31 } lenmem = uintptr(old.len) \u003c\u003c shift newlenmem = uintptr(cap) \u003c\u003c shift capmem = roundupsize(uintptr(newcap) \u003c\u003c shift) overflow = uintptr(newcap) \u003e (maxAlloc \u003e\u003e shift) newcap = int(capmem \u003e\u003e shift) default: lenmem = uintptr(old.len) * et.size newlenmem = uintptr(cap) * et.size capmem, overflow = math.MulUintptr(et.size, uintptr(newcap)) capmem = roundupsize(capmem) newcap = int(capmem / et.size) } // The check of overflow in addition to capmem \u003e maxAlloc is needed // to prevent an overflow which can be used to trigger a segfault // on 32bit architectures with this example program: // // type T [1\u003c\u003c27 + 1]int64 // // var d T // var s []T // // func main() { // s = append(s, d, d, d, d) // print(len(s), \"\\n\") // } if overflow || capmem \u003e maxAlloc { panic(errorString(\"growslice: cap out of range\")) } var p unsafe.Pointer if et.ptrdata == 0 { p = mallocgc(capmem, nil, false) // The append() that calls growslice is going to overwrite from old.len to cap (which will be the new length). // Only clear the part that will not be overwritten. memclrNoHeapPointers(add(p, newlenmem), capmem-newlenmem) } else { // Note: can't use rawmem (which avoids zeroing of memory), because then GC can scan uninitialized memory. p = mallocgc(capmem, et, true) if lenmem \u003e 0 \u0026\u0026 writeBarrier.enabled { // Only shade the pointers in old.array since we know the destination slice p // only contains nil pointers because it has been cleared during alloc. bulkBarrierPreWriteSr","date":"2020-05-29","objectID":"/go-slice/:3:0","tags":["golang","runtime","slice","源码阅读"],"title":"Golang Slice源码阅读笔记","uri":"/go-slice/"},{"categories":["golang源码阅读"],"content":"工具函数 func panicmakeslicelen() { panic(errorString(\"makeslice: len out of range\")) } func panicmakeslicecap() { panic(errorString(\"makeslice: cap out of range\")) } func isPowerOfTwo(x uintptr) bool { return x\u0026(x-1) == 0 } func slicecopy(to, fm slice, width uintptr) int { if fm.len == 0 || to.len == 0 { return 0 } n := fm.len if to.len \u003c n { n = to.len } if width == 0 { return n } if raceenabled { callerpc := getcallerpc() pc := funcPC(slicecopy) racereadrangepc(fm.array, uintptr(n*int(width)), callerpc, pc) racewriterangepc(to.array, uintptr(n*int(width)), callerpc, pc) } if msanenabled { msanread(fm.array, uintptr(n*int(width))) msanwrite(to.array, uintptr(n*int(width))) } size := uintptr(n) * width if size == 1 { // common case worth about 2x to do here // TODO: is this still worth it with new memmove impl? *(*byte)(to.array) = *(*byte)(fm.array) // known to be a byte pointer } else { memmove(to.array, fm.array, size) } return n } func slicestringcopy(to []byte, fm string) int { if len(fm) == 0 || len(to) == 0 { return 0 } n := len(fm) if len(to) \u003c n { n = len(to) } if raceenabled { callerpc := getcallerpc() pc := funcPC(slicestringcopy) racewriterangepc(unsafe.Pointer(\u0026to[0]), uintptr(n), callerpc, pc) } if msanenabled { msanwrite(unsafe.Pointer(\u0026to[0]), uintptr(n)) } memmove(unsafe.Pointer(\u0026to[0]), stringStructOf(\u0026fm).str, uintptr(n)) return n } ","date":"2020-05-29","objectID":"/go-slice/:4:0","tags":["golang","runtime","slice","源码阅读"],"title":"Golang Slice源码阅读笔记","uri":"/go-slice/"},{"categories":["golang源码阅读"],"content":"Golang的并发是一大特色。写起来真的大快人心。channel作为并发routine之间共享信息的主要手段，是gopher不可不知的杀器。","date":"2020-05-29","objectID":"/go-chan/","tags":["golang","runtime","chan","源码阅读"],"title":"Golang Channel源码阅读笔记","uri":"/go-chan/"},{"categories":["golang源码阅读"],"content":"Golang的并发是一大特色。写起来真的大快人心。channel作为并发routine之间共享信息的主要手段，是gopher不可不知的杀器。眼睛长了麦粒肿，现在只能独眼龙看channel的源码。我还计划写一个select的源码阅读笔记，这个和channel的源码有着无比紧密的联系。 ","date":"2020-05-29","objectID":"/go-chan/:0:0","tags":["golang","runtime","chan","源码阅读"],"title":"Golang Channel源码阅读笔记","uri":"/go-chan/"},{"categories":["golang源码阅读"],"content":"开篇注释 // Invariants: // At least one of c.sendq and c.recvq is empty, // except for the case of an unbuffered channel with a single goroutine // blocked on it for both sending and receiving using a select statement, // in which case the length of c.sendq and c.recvq is limited only by the // size of the select statement. // // For buffered channels, also: // c.qcount \u003e 0 implies that c.recvq is empty. // c.qcount \u003c c.dataqsiz implies that c.sendq is empty. 代码的最开始就用注释给出了channel的“钻石恒久远一颗永流传”：c.sendq和c.recvq就像太阳和月亮，总有一个是空的。 ","date":"2020-05-29","objectID":"/go-chan/:1:0","tags":["golang","runtime","chan","源码阅读"],"title":"Golang Channel源码阅读笔记","uri":"/go-chan/"},{"categories":["golang源码阅读"],"content":"channel相关的定义 const ( maxAlign = 8 hchanSize = unsafe.Sizeof(hchan{}) + uintptr(-int(unsafe.Sizeof(hchan{}))\u0026(maxAlign-1)) debugChan = false ) type hchan struct { qcount uint // total data in the queue dataqsiz uint // size of the circular queue buf unsafe.Pointer // points to an array of dataqsiz elements elemsize uint16 closed uint32 elemtype *_type // element type sendx uint // send index recvx uint // receive index recvq waitq // list of recv waiters sendq waitq // list of send waiters // lock protects all fields in hchan, as well as several // fields in sudogs blocked on this channel. // // Do not change another G's status while holding this lock // (in particular, do not ready a G), as this can deadlock // with stack shrinking. lock mutex } type waitq struct { first *sudog last *sudog } func (q *waitq) enqueue(sgp *sudog) { sgp.next = nil x := q.last if x == nil { sgp.prev = nil q.first = sgp q.last = sgp return } sgp.prev = x x.next = sgp q.last = sgp } func (q *waitq) dequeue() *sudog { for { sgp := q.first if sgp == nil { return nil } y := sgp.next if y == nil { q.first = nil q.last = nil } else { y.prev = nil q.first = y sgp.next = nil // mark as removed (see dequeueSudog) } // if a goroutine was put on this queue because of a // select, there is a small window between the goroutine // being woken up by a different case and it grabbing the // channel locks. Once it has the lock // it removes itself from the queue, so we won't see it after that. // We use a flag in the G struct to tell us when someone // else has won the race to signal this goroutine but the goroutine // hasn't removed itself from the queue yet. if sgp.isSelect \u0026\u0026 !atomic.Cas(\u0026sgp.g.selectDone, 0, 1) { continue } return sgp } } qcount： 数据队列的计数器，如果是unbuffered，那么就永远都是0。 dataqsize： 对于buffered channel，内部维护了一个环形队列，这个队列的长度，一般就是我们make(chan, size)对应的size。 buf： 指向环形队列的指针。 elemsize： 管道传送的数据结构的大小。 closed： 管道是否关闭。 elemtype： 指向传送数据的类型定义。 sendx： 发送消息的缓存下标。 recvx： 接受消息的缓存下标。 recvq： 阻塞在管道的等待接收的sudog的waiting list。 sendq： 阻塞在管道的等待发送的sudog的waiting list。 lock： 保证chan是并发安全。 然后一个waitq的数据结构和它的enqueue,dequeue方法实现。 对于buffered channel，这里给一个buf的示意图。 管道的buffer\" 管道的buffer ","date":"2020-05-29","objectID":"/go-chan/:2:0","tags":["golang","runtime","chan","源码阅读"],"title":"Golang Channel源码阅读笔记","uri":"/go-chan/"},{"categories":["golang源码阅读"],"content":"创建channel //go:linkname reflect_makechan reflect.makechan func reflect_makechan(t *chantype, size int) *hchan { return makechan(t, size) } func makechan64(t *chantype, size int64) *hchan { if int64(int(size)) != size { panic(plainError(\"makechan: size out of range\")) } return makechan(t, int(size)) } func makechan(t *chantype, size int) *hchan { elem := t.elem // compiler checks this but be safe. if elem.size \u003e= 1\u003c\u003c16 { throw(\"makechan: invalid channel element type\") } if hchanSize%maxAlign != 0 || elem.align \u003e maxAlign { throw(\"makechan: bad alignment\") } mem, overflow := math.MulUintptr(elem.size, uintptr(size)) if overflow || mem \u003e maxAlloc-hchanSize || size \u003c 0 { panic(plainError(\"makechan: size out of range\")) } // Hchan does not contain pointers interesting for GC when elements stored in buf do not contain pointers. // buf points into the same allocation, elemtype is persistent. // SudoG's are referenced from their owning thread so they can't be collected. // TODO(dvyukov,rlh): Rethink when collector can move allocated objects. var c *hchan switch { case mem == 0: // Queue or element size is zero. c = (*hchan)(mallocgc(hchanSize, nil, true)) // Race detector uses this location for synchronization. c.buf = c.raceaddr() case elem.ptrdata == 0: // Elements do not contain pointers. // Allocate hchan and buf in one call. c = (*hchan)(mallocgc(hchanSize+mem, nil, true)) c.buf = add(unsafe.Pointer(c), hchanSize) default: // Elements contain pointers. c = new(hchan) c.buf = mallocgc(mem, elem, true) } c.elemsize = uint16(elem.size) c.elemtype = elem c.dataqsiz = uint(size) if debugChan { print(\"makechan: chan=\", c, \"; elemsize=\", elem.size, \"; dataqsiz=\", size, \"\\n\") } return c } makechan(t *chantype, size int)就是我们写go代码时，make(chan)背后的英雄。这也可以看出，为什么我们自己写go代码时候以及面试被拷问的时候，chan为什么要用make来创建，而不是new。 从编译器传入的*chantype中拿出elem，channel中传递的数据结构。 两个边界检测。 检查管道的buffer会不会导致内存的溢出。 分配内存，根据不同的情况有一点优化。如果是无buffer的管道或者管道消息结构的大小是0，直接分配hchan的内存。如果管道消息的结构不含有指针，就在一个alloc中一起分配hchan和buffer的内存。其他情况下，hchan和对应的buffer各自分配内存。 elemsize，elemtype，dataqsiz初始化。 ","date":"2020-05-29","objectID":"/go-chan/:3:0","tags":["golang","runtime","chan","源码阅读"],"title":"Golang Channel源码阅读笔记","uri":"/go-chan/"},{"categories":["golang源码阅读"],"content":"chan \u003c- elem 好长好精彩的send来了。 // entry point for c \u003c- x from compiled code //go:nosplit func chansend1(c *hchan, elem unsafe.Pointer) { chansend(c, elem, true, getcallerpc()) } /* * generic single channel send/recv * If block is not nil, * then the protocol will not * sleep but return if it could * not complete. * * sleep can wake up with g.param == nil * when a channel involved in the sleep has * been closed. it is easiest to loop and re-run * the operation; we'll see that it's now closed. */ func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool { if c == nil { if !block { return false } gopark(nil, nil, waitReasonChanSendNilChan, traceEvGoStop, 2) throw(\"unreachable\") } if debugChan { print(\"chansend: chan=\", c, \"\\n\") } if raceenabled { racereadpc(c.raceaddr(), callerpc, funcPC(chansend)) } // Fast path: check for failed non-blocking operation without acquiring the lock. // // After observing that the channel is not closed, we observe that the channel is // not ready for sending. Each of these observations is a single word-sized read // (first c.closed and second full()). // Because a closed channel cannot transition from 'ready for sending' to // 'not ready for sending', even if the channel is closed between the two observations, // they imply a moment between the two when the channel was both not yet closed // and not ready for sending. We behave as if we observed the channel at that moment, // and report that the send cannot proceed. // // It is okay if the reads are reordered here: if we observe that the channel is not // ready for sending and then observe that it is not closed, that implies that the // channel wasn't closed during the first observation. However, nothing here // guarantees forward progress. We rely on the side effects of lock release in // chanrecv() and closechan() to update this thread's view of c.closed and full(). if !block \u0026\u0026 c.closed == 0 \u0026\u0026 full(c) { return false } var t0 int64 if blockprofilerate \u003e 0 { t0 = cputicks() } lock(\u0026c.lock) if c.closed != 0 { unlock(\u0026c.lock) panic(plainError(\"send on closed channel\")) } if sg := c.recvq.dequeue(); sg != nil { // Found a waiting receiver. We pass the value we want to send // directly to the receiver, bypassing the channel buffer (if any). send(c, sg, ep, func() { unlock(\u0026c.lock) }, 3) return true } if c.qcount \u003c c.dataqsiz { // Space is available in the channel buffer. Enqueue the element to send. qp := chanbuf(c, c.sendx) if raceenabled { raceacquire(qp) racerelease(qp) } typedmemmove(c.elemtype, qp, ep) c.sendx++ if c.sendx == c.dataqsiz { c.sendx = 0 } c.qcount++ unlock(\u0026c.lock) return true } if !block { unlock(\u0026c.lock) return false } // Block on the channel. Some receiver will complete our operation for us. gp := getg() mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. mysg.elem = ep mysg.waitlink = nil mysg.g = gp mysg.isSelect = false mysg.c = c gp.waiting = mysg gp.param = nil c.sendq.enqueue(mysg) gopark(chanparkcommit, unsafe.Pointer(\u0026c.lock), waitReasonChanSend, traceEvGoBlockSend, 2) // Ensure the value being sent is kept alive until the // receiver copies it out. The sudog has a pointer to the // stack object, but sudogs aren't considered as roots of the // stack tracer. KeepAlive(ep) // someone woke us up. if mysg != gp.waiting { throw(\"G waiting list is corrupted\") } gp.waiting = nil gp.activeStackChans = false if gp.param == nil { if c.closed == 0 { throw(\"chansend: spurious wakeup\") } panic(plainError(\"send on closed channel\")) } gp.param = nil if mysg.releasetime \u003e 0 { blockevent(mysg.releasetime-t0, 2) } mysg.c = nil releaseSudog(mysg) return true } chansend1(c *hchan, elem unsafe.Pointer)函数只是chansend的一个简单的封装。还是直奔chansend吧。 如果无聊到给一个chan赋了nil，然后还对他\u003c-，这就是结果。 快速检测如果send不要求阻塞，chan没有被关闭，并且没有准备好接收一个send动作，那么就直接返回false。 获取管道的mtx。接下来，任何显式的返回，都会释放这个锁。 安全检查，对一个已经close的管道，\u003c-会导致panic。 接下来就是各种","date":"2020-05-29","objectID":"/go-chan/:4:0","tags":["golang","runtime","chan","源码阅读"],"title":"Golang Channel源码阅读笔记","uri":"/go-chan/"},{"categories":["golang源码阅读"],"content":"elem := \u003c- chan // entry points for \u003c- c from compiled code //go:nosplit func chanrecv1(c *hchan, elem unsafe.Pointer) { chanrecv(c, elem, true) } //go:nosplit func chanrecv2(c *hchan, elem unsafe.Pointer) (received bool) { _, received = chanrecv(c, elem, true) return } // chanrecv receives on channel c and writes the received data to ep. // ep may be nil, in which case received data is ignored. // If block == false and no elements are available, returns (false, false). // Otherwise, if c is closed, zeros *ep and returns (true, false). // Otherwise, fills in *ep with an element and returns (true, true). // A non-nil ep must point to the heap or the caller's stack. func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) { // raceenabled: don't need to check ep, as it is always on the stack // or is new memory allocated by reflect. if debugChan { print(\"chanrecv: chan=\", c, \"\\n\") } if c == nil { if !block { return } gopark(nil, nil, waitReasonChanReceiveNilChan, traceEvGoStop, 2) throw(\"unreachable\") } // Fast path: check for failed non-blocking operation without acquiring the lock. if !block \u0026\u0026 empty(c) { // After observing that the channel is not ready for receiving, we observe whether the // channel is closed. // // Reordering of these checks could lead to incorrect behavior when racing with a close. // For example, if the channel was open and not empty, was closed, and then drained, // reordered reads could incorrectly indicate \"open and empty\". To prevent reordering, // we use atomic loads for both checks, and rely on emptying and closing to happen in // separate critical sections under the same lock. This assumption fails when closing // an unbuffered channel with a blocked send, but that is an error condition anyway. if atomic.Load(\u0026c.closed) == 0 { // Because a channel cannot be reopened, the later observation of the channel // being not closed implies that it was also not closed at the moment of the // first observation. We behave as if we observed the channel at that moment // and report that the receive cannot proceed. return } // The channel is irreversibly closed. Re-check whether the channel has any pending data // to receive, which could have arrived between the empty and closed checks above. // Sequential consistency is also required here, when racing with such a send. if empty(c) { // The channel is irreversibly closed and empty. if raceenabled { raceacquire(c.raceaddr()) } if ep != nil { typedmemclr(c.elemtype, ep) } return true, false } } var t0 int64 if blockprofilerate \u003e 0 { t0 = cputicks() } lock(\u0026c.lock) if c.closed != 0 \u0026\u0026 c.qcount == 0 { if raceenabled { raceacquire(c.raceaddr()) } unlock(\u0026c.lock) if ep != nil { typedmemclr(c.elemtype, ep) } return true, false } if sg := c.sendq.dequeue(); sg != nil { // Found a waiting sender. If buffer is size 0, receive value // directly from sender. Otherwise, receive from head of queue // and add sender's value to the tail of the queue (both map to // the same buffer slot because the queue is full). recv(c, sg, ep, func() { unlock(\u0026c.lock) }, 3) return true, true } if c.qcount \u003e 0 { // Receive directly from queue qp := chanbuf(c, c.recvx) if raceenabled { raceacquire(qp) racerelease(qp) } if ep != nil { typedmemmove(c.elemtype, ep, qp) } typedmemclr(c.elemtype, qp) c.recvx++ if c.recvx == c.dataqsiz { c.recvx = 0 } c.qcount-- unlock(\u0026c.lock) return true, true } if !block { unlock(\u0026c.lock) return false, false } // no sender available: block on this channel. gp := getg() mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. mysg.elem = ep mysg.waitlink = nil gp.waiting = mysg mysg.g = gp mysg.isSelect = false mysg.c = c gp.param = nil c.recvq.enqueue(mysg) gopark(chanparkcommit, unsafe.Pointer(\u0026c.lock), waitReasonChanReceive, traceEvGoBlockRecv, 2) // someone woke us up if mysg != gp.waiting { throw(\"G waiting l","date":"2020-05-29","objectID":"/go-chan/:5:0","tags":["golang","runtime","chan","源码阅读"],"title":"Golang Channel源码阅读笔记","uri":"/go-chan/"},{"categories":["golang源码阅读"],"content":"关闭channel func closechan(c *hchan) { if c == nil { panic(plainError(\"close of nil channel\")) } lock(\u0026c.lock) if c.closed != 0 { unlock(\u0026c.lock) panic(plainError(\"close of closed channel\")) } if raceenabled { callerpc := getcallerpc() racewritepc(c.raceaddr(), callerpc, funcPC(closechan)) racerelease(c.raceaddr()) } c.closed = 1 var glist gList // release all readers for { sg := c.recvq.dequeue() if sg == nil { break } if sg.elem != nil { typedmemclr(c.elemtype, sg.elem) sg.elem = nil } if sg.releasetime != 0 { sg.releasetime = cputicks() } gp := sg.g gp.param = nil if raceenabled { raceacquireg(gp, c.raceaddr()) } glist.push(gp) } // release all writers (they will panic) for { sg := c.sendq.dequeue() if sg == nil { break } sg.elem = nil if sg.releasetime != 0 { sg.releasetime = cputicks() } gp := sg.g gp.param = nil if raceenabled { raceacquireg(gp, c.raceaddr()) } glist.push(gp) } unlock(\u0026c.lock) // Ready all Gs now that we've dropped the channel lock. for !glist.empty() { gp := glist.pop() gp.schedlink = 0 goready(gp, 3) } } 关闭一个nil的channel，panic没什么好说的。 锁住当前channel。 如果channel已经被关闭了，panic，没什么好说的，常识。 标记c.closed = 1。 循环拿出所有当前recvq队列里等待的sg，标记是channel关闭导致的唤醒。从sg里得到g，推到glist里。 循环拿出所有当前sendq队列里等待的sg，标记是channel关闭导致的唤醒。把相应的g推到glist里。(这些g最终会panic，常识)。 把glist里所有的g都设为就绪(唤醒)。 ","date":"2020-05-29","objectID":"/go-chan/:6:0","tags":["golang","runtime","chan","源码阅读"],"title":"Golang Channel源码阅读笔记","uri":"/go-chan/"},{"categories":["golang源码阅读"],"content":"工具函数 // chanbuf(c, i) is pointer to the i'th slot in the buffer. func chanbuf(c *hchan, i uint) unsafe.Pointer { return add(c.buf, uintptr(i)*uintptr(c.elemsize)) } // full reports whether a send on c would block (that is, the channel is full). // It uses a single word-sized read of mutable state, so although // the answer is instantaneously true, the correct answer may have changed // by the time the calling function receives the return value. func full(c *hchan) bool { // c.dataqsiz is immutable (never written after the channel is created) // so it is safe to read at any time during channel operation. if c.dataqsiz == 0 { // Assumes that a pointer read is relaxed-atomic. return c.recvq.first == nil } // Assumes that a uint read is relaxed-atomic. return c.qcount == c.dataqsiz } // Sends and receives on unbuffered or empty-buffered channels are the // only operations where one running goroutine writes to the stack of // another running goroutine. The GC assumes that stack writes only // happen when the goroutine is running and are only done by that // goroutine. Using a write barrier is sufficient to make up for // violating that assumption, but the write barrier has to work. // typedmemmove will call bulkBarrierPreWrite, but the target bytes // are not in the heap, so that will not help. We arrange to call // memmove and typeBitsBulkBarrier instead. func sendDirect(t *_type, sg *sudog, src unsafe.Pointer) { // src is on our stack, dst is a slot on another stack. // Once we read sg.elem out of sg, it will no longer // be updated if the destination's stack gets copied (shrunk). // So make sure that no preemption points can happen between read \u0026 use. dst := sg.elem typeBitsBulkBarrier(t, uintptr(dst), uintptr(src), t.size) // No need for cgo write barrier checks because dst is always // Go memory. memmove(dst, src, t.size) } func recvDirect(t *_type, sg *sudog, dst unsafe.Pointer) { // dst is on our stack or the heap, src is on another stack. // The channel is locked, so src will not move during this // operation. src := sg.elem typeBitsBulkBarrier(t, uintptr(dst), uintptr(src), t.size) memmove(dst, src, t.size) } // empty reports whether a read from c would block (that is, the channel is // empty). It uses a single atomic read of mutable state. func empty(c *hchan) bool { // c.dataqsiz is immutable. if c.dataqsiz == 0 { return atomic.Loadp(unsafe.Pointer(\u0026c.sendq.first)) == nil } return atomic.Loaduint(\u0026c.qcount) == 0 } ","date":"2020-05-29","objectID":"/go-chan/:7:0","tags":["golang","runtime","chan","源码阅读"],"title":"Golang Channel源码阅读笔记","uri":"/go-chan/"},{"categories":["golang源码阅读"],"content":"select里的chan操作，神有特殊的安排 主要是chansend和chanrecv的封装，调用时block参数都是false，所以select不会因为channel而阻塞。 // compiler implements // // select { // case c \u003c- v: // ... foo // default: // ... bar // } // // as // // if selectnbsend(c, v) { // ... foo // } else { // ... bar // } // func selectnbsend(c *hchan, elem unsafe.Pointer) (selected bool) { return chansend(c, elem, false, getcallerpc()) } // compiler implements // // select { // case v = \u003c-c: // ... foo // default: // ... bar // } // // as // // if selectnbrecv(\u0026v, c) { // ... foo // } else { // ... bar // } // func selectnbrecv(elem unsafe.Pointer, c *hchan) (selected bool) { selected, _ = chanrecv(c, elem, false) return } // compiler implements // // select { // case v, ok = \u003c-c: // ... foo // default: // ... bar // } // // as // // if c != nil \u0026\u0026 selectnbrecv2(\u0026v, \u0026ok, c) { // ... foo // } else { // ... bar // } // func selectnbrecv2(elem unsafe.Pointer, received *bool, c *hchan) (selected bool) { // TODO(khr): just return 2 values from this function, now that it is in Go. selected, *received = chanrecv(c, elem, false) return } ","date":"2020-05-29","objectID":"/go-chan/:8:0","tags":["golang","runtime","chan","源码阅读"],"title":"Golang Channel源码阅读笔记","uri":"/go-chan/"},{"categories":["golang源码阅读"],"content":"TODO func chanparkcommit(gp *g, chanLock unsafe.Pointer) bool { // There are unlocked sudogs that point into gp's stack. Stack // copying must lock the channels of those sudogs. gp.activeStackChans = true unlock((*mutex)(chanLock)) return true } ","date":"2020-05-29","objectID":"/go-chan/:9:0","tags":["golang","runtime","chan","源码阅读"],"title":"Golang Channel源码阅读笔记","uri":"/go-chan/"},{"categories":["golang源码阅读"],"content":"最近，终于找了时间耐着性子读了go的map的实现，挺有意思的，没有想到map是这样实现的。这里做一些阅读的笔记。细节都是魔鬼。","date":"2020-05-26","objectID":"/go-map/","tags":["golang","runtime","map","源码阅读"],"title":"Golang Map源码阅读笔记","uri":"/go-map/"},{"categories":["golang源码阅读"],"content":"最近，终于找了时间耐着性子读了go的map的实现，挺有意思的，没有想到map是这样实现的。 这里做一些阅读的笔记。 大体上是跟着代码顺序记录(jump to defination)。 细节都是魔鬼。 ","date":"2020-05-26","objectID":"/go-map/:0:0","tags":["golang","runtime","map","源码阅读"],"title":"Golang Map源码阅读笔记","uri":"/go-map/"},{"categories":["golang源码阅读"],"content":"开篇的注释，高度浓缩了整个map的设计理念 // A map is just a hash tableG The data is arranged // into an array of buckets. Each bucket contains up to // 8 key/elem pairs. The low-order bits of the hash are // used to select a bucket. Each bucket contains a few // high-order bits of each hash to distinguish the entries // within a single bucket. // // If more than 8 keys hash to a bucket, we chain on // extra buckets. // // When the hashtable grows, we allocate a new array // of buckets twice as big. Buckets are incrementally // copied from the old bucket array to the new bucket array. // // Map iterators walk through the array of buckets and // return the keys in walk order (bucket #, then overflow // chain order, then bucket index). To maintain iteration // semantics, we never move keys within their bucket (if // we did, keys might be returned 0 or 2 times). When // growing the table, iterators remain iterating through the // old table and must check the new table if the bucket // they are iterating through has been moved (\"evacuated\") // to the new table. map就是一个hash表，这个没有什么可疑惑的。这个hash表内部的数据元素并不是简单的key到value的映射，如果这么直白，那这个也没有什么好看的了。 hash表内部的数据其实是以一个叫bucket的数据结构作为组织存储的单位，所以整个hash表基本上就是一个包含若干bucket的数组。bucket的具体定义在后面跟着代码的结构走到的时候再细说。先来看看宏观的定义。每一个bucket都包含8个键值对，这个8是严格定义的，所以即使是一个空的bucket，也依然有占8个键值对的内存空间被分配给了bucket。 一个key被hash后等到一个哈希值，然后go会用这个哈希值的’low-order bits’去定位数据存储的bucket。当定位到目标bucket之后，（我们先假设当前是写访问），如果有空余的键值对空间（刚才说过的一定分配的8个键值对空间），那就直接在下一个空闲的键值对空间写入key和elem，并且在该bucket里面写入当前key的tophash作为key的索引，供访问的时候进行快速查找（就是一个索引，tophash后面在代码里再说）。如果当前定位到的bucket已经存满了8个键值之后，那么go会采用一个链结构去链接一个新的bucket来给这个hash对应的存储空间扩容，这个新的bucket被称为overflow bucket。 然后当map剩余空间吃紧或者含有太多的overflow bucket的时候，map会自动扩容，每次扩容都是之前的2倍大小。 // Picking loadFactor: too large and we have lots of overflow // buckets, too small and we waste a lot of space. I wrote // a simple program to check some stats for different loads: // (64-bit, 8 byte keys and elems) // loadFactor %overflow bytes/entry hitprobe missprobe // 4.00 2.13 20.77 3.00 4.00 // 4.50 4.05 17.30 3.25 4.50 // 5.00 6.85 14.77 3.50 5.00 // 5.50 10.55 12.94 3.75 5.50 // 6.00 15.27 11.67 4.00 6.00 // 6.50 20.90 10.79 4.25 6.50 // 7.00 27.14 10.15 4.50 7.00 // 7.50 34.03 9.73 4.75 7.50 // 8.00 41.10 9.40 5.00 8.00 // // %overflow = percentage of buckets which have an overflow bucket // bytes/entry = overhead bytes used per key/elem pair // hitprobe = # of entries to check when looking up a present key // missprobe = # of entries to check when looking up an absent key // // Keep in mind this data is for maximally loaded tables, i.e. just // before the table grows. Typical tables will be somewhat less loaded. 这个表似乎是一些测试数据，只能说，需要的时候来参考一下。 ","date":"2020-05-26","objectID":"/go-map/:1:0","tags":["golang","runtime","map","源码阅读"],"title":"Golang Map源码阅读笔记","uri":"/go-map/"},{"categories":["golang源码阅读"],"content":"定义的常量 const ( // 每个bucket包含的键值对数量：8 //Maximum number of key/elem pairs a bucket can hold. bucketCntBits = 3 bucketCnt = 1 \u003c\u003c bucketCntBits // 计算map当前的负载，如果超过这个负载，就会出发扩容 // Maximum average load of a bucket that triggers growth is 6.5. // Represent as loadFactorNum/loadFactorDen, to allow integer math. loadFactorNum = 13 loadFactorDen = 2 // Maximum key or elem size to keep inline (instead of mallocing per element). // Must fit in a uint8. // Fast versions cannot handle big elems - the cutoff size for // fast versions in cmd/compile/internal/gc/walk.go must be at most this elem. maxKeySize = 128 maxElemSize = 128 // 这个是获取在一个bucket结构里键值对存储空间的内存偏移量， // 这个设计是因为在bucket的结构定义里没有直接定义字段，而是通过指针+偏移量来直接访问的。 // data offset should be the size of the bmap struct, but needs to be // aligned correctly. For amd64p32 this means 64-bit alignment // even though pointers are 32 bit. dataOffset = unsafe.Offsetof(struct { b bmap v int64 }{}.v) // 每个bucket内部，还有一个键值对的索引 // 空置的键值对所对应的索引里面存的是标记状态，例如当前是最后的一个元素，或者是因为扩容已经把这个键值对迁移走了等等。 // 如果键值对不为空的话，这里存的是索引的值， key的哈希值的高8位，可以快速找到bucket中的键值对 // Possible tophash values. We reserve a few possibilities for special marks. // Each bucket (including its overflow buckets, if any) will have either all or none of its // entries in the evacuated* states (except during the evacuate() method, which only happens // during map writes and thus no one else can observe the map during that time). emptyRest = 0 // this cell is empty, and there are no more non-empty cells at higher indexes or overflows. emptyOne = 1 // this cell is empty // 这两个值在扩容的时候会很重要，根据growth是原大小，还是2倍大小，分别使用x或者y evacuatedX = 2 // key/elem is valid. Entry has been evacuated to first half of larger table. evacuatedY = 3 // same as above, but evacuated to second half of larger table. evacuatedEmpty = 4 // cell is empty, bucket is evacuated. minTopHash = 5 // minimum tophash for a normal filled cell. // flags iterator = 1 // there may be an iterator using buckets oldIterator = 2 // there may be an iterator using oldbuckets hashWriting = 4 // a goroutine is writing to the map sameSizeGrow = 8 // the current map growth is to a new map of the same size // sentinel bucket ID for iterator checks noCheck = 1\u003c\u003c(8*sys.PtrSize) - 1 ) ","date":"2020-05-26","objectID":"/go-map/:2:0","tags":["golang","runtime","map","源码阅读"],"title":"Golang Map源码阅读笔记","uri":"/go-map/"},{"categories":["golang源码阅读"],"content":"map header定义 // A header for a Go map. type hmap struct { // Note: the format of the hmap is also encoded in cmd/compile/internal/gc/reflect.go. // Make sure this stays in sync with the compiler's definition. count int // # live cells == size of map. Must be first (used by len() builtin) flags uint8 B uint8 // log_2 of # of buckets (can hold up to loadFactor * 2^B items) noverflow uint16 // approximate number of overflow buckets; see incrnoverflow for details hash0 uint32 // hash seed buckets unsafe.Pointer // array of 2^B Buckets. may be nil if count==0. oldbuckets unsafe.Pointer // previous bucket array of half the size, non-nil only when growing nevacuate uintptr // progress counter for evacuation (buckets less than this have been evacuated) extra *mapextra // optional fields } 这个就是map在runtime里面的定义了。 count 是map内存储数据的计数器 flags 是map运行状态的一些标志位，碰到了会说明的 B 是一个很重要的参数。为什么叫B我不知道，但是这个B表示了当前map直接默认分配的bucket: 2的B次方个bucket。分配的是连续的内存片段，通过指针来进行检索，并且实际分配的bucket数量可能会大于这个数字，作为预分配的overflow bucket。 noverflow map所有的overflow bucket的数量，这是一个概数。在B比较小的时候，它是一个精确数字，B超过一定的大小之后，它只是一个概数。 hash0 用来做Hash运算的种子。 buckets 这也是一个重要的字段。要注意它的类型并不是* bucket，而是一个普通的unsafe.Pointer。这是因为一个map所有的bucket都是通过这个指针访问。因为分配的bucket是一段连续的内存，所以，通过指针+偏移量，可以访问任何你想要的bucket。那这个offset我们等到代码出现的时候再说。 oldbuckets 是在map扩容时持有扩容前的bucket。 nevacuate 在扩容时，记录扩容迁移进程的，偏移量小于这个值的bucket都是已经被迁移过了。 extra 包含了一些可选的字段，不是每一个map都会有这个字段。 ","date":"2020-05-26","objectID":"/go-map/:3:0","tags":["golang","runtime","map","源码阅读"],"title":"Golang Map源码阅读笔记","uri":"/go-map/"},{"categories":["golang源码阅读"],"content":"mapextra的定义 // mapextra holds fields that are not present on all maps. type mapextra struct { // If both key and elem do not contain pointers and are inline, then we mark bucket // type as containing no pointers. This avoids scanning such maps. // However, bmap.overflow is a pointer. In order to keep overflow buckets // alive, we store pointers to all overflow buckets in hmap.extra.overflow and hmap.extra.oldoverflow. // overflow and oldoverflow are only used if key and elem do not contain pointers. // overflow contains overflow buckets for hmap.buckets. // oldoverflow contains overflow buckets for hmap.oldbuckets. // The indirection allows to store a pointer to the slice in hiter. overflow *[]*bmap oldoverflow *[]*bmap // nextOverflow holds a pointer to a free overflow bucket. nextOverflow *bmap } 这个简单翻译一下： 如果key和elem都不包含指针并且是内联的话，那么我们就标记bucket的类型是不含有指针的。为了保持overflow buckets存活，我们在这个hmap.extra.overflow和hmap.extra.oldoverflow里为每一个overflow bucket保存一个指针。只有在key和elem都不包含指针的情况下，才会使用overflow和oldoverflow。overflow存的都是指向hmap.buckets的overflow bucket，oldoverflow同理。然后这两个字段采用了指向切片的指针是为了能在hiter中也保存一个指针的副本。 最后这个nextOverflow是一个bucket的指针，指向下一个未被使用的overflow bucket。 ","date":"2020-05-26","objectID":"/go-map/:4:0","tags":["golang","runtime","map","源码阅读"],"title":"Golang Map源码阅读笔记","uri":"/go-map/"},{"categories":["golang源码阅读"],"content":"有请bucket的定义 // A bucket for a Go map. type bmap struct { // tophash generally contains the top byte of the hash value // for each key in this bucket. If tophash[0] \u003c minTopHash, // tophash[0] is a bucket evacuation state instead. tophash [bucketCnt]uint8 // Followed by bucketCnt keys and then bucketCnt elems. // NOTE: packing all the keys together and then all the elems together makes the // code a bit more complicated than alternating key/elem/key/elem/... but it allows // us to eliminate padding which would be needed for, e.g., map[int64]int8. // Followed by an overflow pointer. } 当我第一次看到这里的时候，还是很惊讶的，为什么感觉很麻烦的bucket，却只有这么简单的结构定义？这个tophash又是用来干嘛的？ 注释给我们讲的已经很清楚了。 这个tophash是一个uint8的数组，数组大小就是8。刚好是每一个bucket所包含的键值对的个数。这不是一个巧合，它确实是为每一个键值对服务的。大体上来说，这个tophash里面存的值有两个作用：1.用key的hash值的最高byte作为索引值。2.参考前面定义的常量，tophash值的0~4都预留给了状态定义，在满足条件的时候这里就会存对应的状态值。 但其实bmap的结构，并不是这样简单结束了。在tophash后面还有两个隐藏的字段，没有字段名，一个是指向分配的键值对空间，另一个是当前bucket的overflow bucket的指针。 之所以这样实现，我猜是因为map可以存放各种类型key和elem，没有办法预先知道这个键值对空间的大小，（说白了就是没有范型我觉得，也有可能是节约空间的优化）。这也是为什么我们会在常量定义里面看到dataOffset那个偏移量的定义了。 所以刚才我们提到的所有的bucket，在代码实现层面都是一个bmap或者是一个bmap的指针。 还有一点要说明的，键值对的存储并不是key1/elem1/key2/elem2…这样的，而是key1/key2/…key8/elem1/elem2…elem8这样的，说因为这样可以避免一些不必要的内存对齐问题，比如map[int64]int8。 这图从网上找的，凑合看一下，overflow没有\" 这图从网上找的，凑合看一下，overflow没有 ","date":"2020-05-26","objectID":"/go-map/:5:0","tags":["golang","runtime","map","源码阅读"],"title":"Golang Map源码阅读笔记","uri":"/go-map/"},{"categories":["golang源码阅读"],"content":"hmap给bmap分配overflow // incrnoverflow increments h.noverflow. // noverflow counts the number of overflow buckets. // This is used to trigger same-size map growth. // See also tooManyOverflowBuckets. // To keep hmap small, noverflow is a uint16. // When there are few buckets, noverflow is an exact count. // When there are many buckets, noverflow is an approximate count. func (h *hmap) incrnoverflow() { // We trigger same-size map growth if there are // as many overflow buckets as buckets. // We need to be able to count to 1\u003c\u003ch.B. if h.B \u003c 16 { h.noverflow++ return } // Increment with probability 1/(1\u003c\u003c(h.B-15)). // When we reach 1\u003c\u003c15 - 1, we will have approximately // as many overflow buckets as buckets. mask := uint32(1)\u003c\u003c(h.B-15) - 1 // Example: if h.B == 18, then mask == 7, // and fastrand \u0026 7 == 0 with probability 1/8. if fastrand()\u0026mask == 0 { h.noverflow++ } } func (h *hmap) newoverflow(t *maptype, b *bmap) *bmap { var ovf *bmap if h.extra != nil \u0026\u0026 h.extra.nextOverflow != nil { // We have preallocated overflow buckets available. // See makeBucketArray for more details. ovf = h.extra.nextOverflow if ovf.overflow(t) == nil { // We're not at the end of the preallocated overflow buckets. Bump the pointer. h.extra.nextOverflow = (*bmap)(add(unsafe.Pointer(ovf), uintptr(t.bucketsize))) } else { // This is the last preallocated overflow bucket. // Reset the overflow pointer on this bucket, // which was set to a non-nil sentinel value. ovf.setoverflow(t, nil) h.extra.nextOverflow = nil } } else { ovf = (*bmap)(newobject(t.bucket)) } h.incrnoverflow() if t.bucket.ptrdata == 0 { h.createOverflow() *h.extra.overflow = append(*h.extra.overflow, ovf) } b.setoverflow(t, ovf) return ovf } func (h *hmap) createOverflow() { if h.extra == nil { h.extra = new(mapextra) } if h.extra.overflow == nil { h.extra.overflow = new([]*bmap) } } newoverflow用来创建分配一个新的bucket对象，在内部会调用这另外的两个函数。我们就来顺着newoverflow看一下代码，逻辑是很简单的。 首先检查hmap.extra和hmap.extra.nextOverflow。 如果都不为空的话，就说明我们之前在map扩容的时候预先分配了用做overflow的bucket了。这个时候我们只需要调用hmap.extra.nextOverflow的overflow(t)方法获取nextOverflow指向的bucket的overflow bucket。因为是预先分配的overflow，我们不知道这些overflow的占用情况，所以要先判断一下，是否依然有可用的overflow bucket。这里呢，就要根据预先设计好的规则来检查，我们在后面的代码会看到这个地方分配的overflow采用的是将自己的overflow(t)设为一个非空值（作为哨兵）来表示自己是这一片overflow bucket的队尾。这里如果看到自己已经是队尾了，就会把这个哨兵值给删掉，设为nil，并且同时将nextOverflow也置为nil，表示预分配的这些overflow已经全部用完，没有nextOverflow可以用了。而如果不是队尾，那么就直接简单的把下一个overflow bucket的地址放到hmap.extra.nextOverflow里面，就结束了。ovf此时就拿到了有效的*overflow bucket`。 其他情况下，直接调用newobject(t.bucket)来分配新的内存对象赋给ovf。 调用hmap.incrnoverflow增加overflow bucket的计数器，在incrnoverflow方法里面，会根据hmap.B的大小，来决定这个计数器是否准确计数。 如果t.bucket.ptrdata == 0，这个就表示当前的map类型key和elem都不包含指针，这么这个时候就直接调用hmap.createOverflow创建hmap.extra.overflow（如果不存在），然后直接把当前获得的overflow bucket指针加入到hmap.extra.overflow切片中保存。 把ovf指向的bucket设置为当前bucket的overflow，然后返回这个ovf。 ","date":"2020-05-26","objectID":"/go-map/:6:0","tags":["golang","runtime","map","源码阅读"],"title":"Golang Map源码阅读笔记","uri":"/go-map/"},{"categories":["golang源码阅读"],"content":"华丽丽的创建map // makemap implements Go map creation for make(map[k]v, hint). // If the compiler has determined that the map or the first bucket // can be created on the stack, h and/or bucket may be non-nil. // If h != nil, the map can be created directly in h. // If h.buckets != nil, bucket pointed to can be used as the first bucket. func makemap(t *maptype, hint int, h *hmap) *hmap { mem, overflow := math.MulUintptr(uintptr(hint), t.bucket.size) if overflow || mem \u003e maxAlloc { hint = 0 } // initialize Hmap if h == nil { h = new(hmap) } h.hash0 = fastrand() // Find the size parameter B which will hold the requested # of elements. // For hint \u003c 0 overLoadFactor returns false since hint \u003c bucketCnt. B := uint8(0) for overLoadFactor(hint, B) { B++ } h.B = B // allocate initial hash table // if B == 0, the buckets field is allocated lazily later (in mapassign) // If hint is large zeroing this memory could take a while. if h.B != 0 { var nextOverflow *bmap h.buckets, nextOverflow = makeBucketArray(t, h.B, nil) if nextOverflow != nil { h.extra = new(mapextra) h.extra.nextOverflow = nextOverflow } } return h } // makeBucketArray initializes a backing array for map buckets. // 1\u003c\u003cb is the minimum number of buckets to allocate. // dirtyalloc should either be nil or a bucket array previously // allocated by makeBucketArray with the same t and b parameters. // If dirtyalloc is nil a new backing array will be alloced and // otherwise dirtyalloc will be cleared and reused as backing array. func makeBucketArray(t *maptype, b uint8, dirtyalloc unsafe.Pointer) (buckets unsafe.Pointer, nextOverflow *bmap) { base := bucketShift(b) nbuckets := base // For small b, overflow buckets are unlikely. // Avoid the overhead of the calculation. if b \u003e= 4 { // Add on the estimated number of overflow buckets // required to insert the median number of elements // used with this value of b. nbuckets += bucketShift(b - 4) sz := t.bucket.size * nbuckets up := roundupsize(sz) if up != sz { nbuckets = up / t.bucket.size } } if dirtyalloc == nil { buckets = newarray(t.bucket, int(nbuckets)) } else { // dirtyalloc was previously generated by // the above newarray(t.bucket, int(nbuckets)) // but may not be empty. buckets = dirtyalloc size := t.bucket.size * nbuckets if t.bucket.ptrdata != 0 { memclrHasPointers(buckets, size) } else { memclrNoHeapPointers(buckets, size) } } if base != nbuckets { // We preallocated some overflow buckets. // To keep the overhead of tracking these overflow buckets to a minimum, // we use the convention that if a preallocated overflow bucket's overflow // pointer is nil, then there are more available by bumping the pointer. // We need a safe non-nil pointer for the last overflow bucket; just use buckets. nextOverflow = (*bmap)(add(buckets, base*uintptr(t.bucketsize))) last := (*bmap)(add(buckets, (nbuckets-1)*uintptr(t.bucketsize))) last.setoverflow(t, (*bmap)(buckets)) } return buckets, nextOverflow } 这两个函数就是主要的负责创建map的家伙。 函数makemap对应的就是我们平时在写golang代码的时候，会经常写的make(map[key]elem, size)。这里compiler会自己做一些处理，不去深究，对我们看代码没有影响。简单理解，size就是hint。 先检查hint和t.bucket.size是否会造成内存分配的溢出，如果溢出或者是需要的内存大小超过了分配内存的上限，那么这个hint会被置为0。 new一个hmap，调用fastrand()产生一个计算hash的随机种子。 根据loadfactor，找到一个满足hint的参数B，赋给hmap.B。 如果B大于0的话，就调用makeBucketArray分配相应的bucket数组空间。并且，如果返回的nextOverflow如果不为空，那么就在hmap里初始化好hmap.extra和hmap.extra.nextOverflow。 函数makeBucketArray才是真正的把创建map时的脏活累活全都给包了。在这个函数里，就会出现前面说的至少分配1 \u003c\u003c hmap.B个bucket。最后一个参数，dirtyalloc如果传空值，那么bucket数组会新分配内存，但是如果传了一个之前分配的bucket数组指针，那么就会使用这个之前分配的内存空间来作为bucket数组，不会向系统新申请alloc。 调用函数bucketShift(b)得到需要分配的最少bucket数量base。 如果 b \u003e 4，那么在base的基础上再增加1 \u003c\u003c (b-4)个bucket，再经过roundup和对齐之后，得到真实创建的bucket数量nbuckets。 如果dirtyalloc为空，那么直接调用newarray(t.bucket, int(nbuckets))，新创建一个nbuckets × t.bucket大小的数组。 如果dirtyalloc不为空，那么就把指向的内存空间重置清空，作为当前的bucket空间。 base != nbuckets就意味着之前计算实际分配bucket数量的时候，包含了一部分预分配的overflow bucket。这其中偏移量小于base * t.bucketsize的都是bucket，这之后的都是overflow bucket。然后，还记得我们之前说的“预分配overflow bucket的队尾哨兵”吗？这里最后一句话last.setoverflow(t, (*bmap)(buckets))就是","date":"2020-05-26","objectID":"/go-map/:7:0","tags":["golang","runtime","map","源码阅读"],"title":"Golang Map源码阅读笔记","uri":"/go-map/"},{"categories":["golang源码阅读"],"content":"若干个map访问的函数 // mapaccess1 returns a pointer to h[key]. Never returns nil, instead // it will return a reference to the zero object for the elem type if // the key is not in the map. // NOTE: The returned pointer may keep the whole map live, so don't // hold onto it for very long. func mapaccess1(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { if raceenabled \u0026\u0026 h != nil { callerpc := getcallerpc() pc := funcPC(mapaccess1) racereadpc(unsafe.Pointer(h), callerpc, pc) raceReadObjectPC(t.key, key, callerpc, pc) } if msanenabled \u0026\u0026 h != nil { msanread(key, t.key.size) } if h == nil || h.count == 0 { if t.hashMightPanic() { t.hasher(key, 0) // see issue 23734 } return unsafe.Pointer(\u0026zeroVal[0]) } if h.flags\u0026hashWriting != 0 { throw(\"concurrent map read and map write\") } hash := t.hasher(key, uintptr(h.hash0)) m := bucketMask(h.B) b := (*bmap)(add(h.buckets, (hash\u0026m)*uintptr(t.bucketsize))) if c := h.oldbuckets; c != nil { if !h.sameSizeGrow() { // There used to be half as many buckets; mask down one more power of two. m \u003e\u003e= 1 } oldb := (*bmap)(add(c, (hash\u0026m)*uintptr(t.bucketsize))) if !evacuated(oldb) { b = oldb } } top := tophash(hash) bucketloop: for ; b != nil; b = b.overflow(t) { for i := uintptr(0); i \u003c bucketCnt; i++ { if b.tophash[i] != top { if b.tophash[i] == emptyRest { break bucketloop } continue } k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if t.indirectkey() { k = *((*unsafe.Pointer)(k)) } if t.key.equal(key, k) { e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize)) if t.indirectelem() { e = *((*unsafe.Pointer)(e)) } return e } } } return unsafe.Pointer(\u0026zeroVal[0]) } func mapaccess2(t *maptype, h *hmap, key unsafe.Pointer) (unsafe.Pointer, bool) { if raceenabled \u0026\u0026 h != nil { callerpc := getcallerpc() pc := funcPC(mapaccess2) racereadpc(unsafe.Pointer(h), callerpc, pc) raceReadObjectPC(t.key, key, callerpc, pc) } if msanenabled \u0026\u0026 h != nil { msanread(key, t.key.size) } if h == nil || h.count == 0 { if t.hashMightPanic() { t.hasher(key, 0) // see issue 23734 } return unsafe.Pointer(\u0026zeroVal[0]), false } if h.flags\u0026hashWriting != 0 { throw(\"concurrent map read and map write\") } hash := t.hasher(key, uintptr(h.hash0)) m := bucketMask(h.B) b := (*bmap)(unsafe.Pointer(uintptr(h.buckets) + (hash\u0026m)*uintptr(t.bucketsize))) if c := h.oldbuckets; c != nil { if !h.sameSizeGrow() { // There used to be half as many buckets; mask down one more power of two. m \u003e\u003e= 1 } oldb := (*bmap)(unsafe.Pointer(uintptr(c) + (hash\u0026m)*uintptr(t.bucketsize))) if !evacuated(oldb) { b = oldb } } top := tophash(hash) bucketloop: for ; b != nil; b = b.overflow(t) { for i := uintptr(0); i \u003c bucketCnt; i++ { if b.tophash[i] != top { if b.tophash[i] == emptyRest { break bucketloop } continue } k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if t.indirectkey() { k = *((*unsafe.Pointer)(k)) } if t.key.equal(key, k) { e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize)) if t.indirectelem() { e = *((*unsafe.Pointer)(e)) } return e, true } } } return unsafe.Pointer(\u0026zeroVal[0]), false } // returns both key and elem. Used by map iterator func mapaccessK(t *maptype, h *hmap, key unsafe.Pointer) (unsafe.Pointer, unsafe.Pointer) { if h == nil || h.count == 0 { return nil, nil } hash := t.hasher(key, uintptr(h.hash0)) m := bucketMask(h.B) b := (*bmap)(unsafe.Pointer(uintptr(h.buckets) + (hash\u0026m)*uintptr(t.bucketsize))) if c := h.oldbuckets; c != nil { if !h.sameSizeGrow() { // There used to be half as many buckets; mask down one more power of two. m \u003e\u003e= 1 } oldb := (*bmap)(unsafe.Pointer(uintptr(c) + (hash\u0026m)*uintptr(t.bucketsize))) if !evacuated(oldb) { b = oldb } } top := tophash(hash) bucketloop: for ; b != nil; b = b.overflow(t) { for i := uintptr(0); i \u003c bucketCnt; i++ { if b.tophash[i] != top { if b.tophash[i] == emptyRest { break bucketloop } continue } k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if t.indirectkey() { k = *((*u","date":"2020-05-26","objectID":"/go-map/:8:0","tags":["golang","runtime","map","源码阅读"],"title":"Golang Map源码阅读笔记","uri":"/go-map/"},{"categories":["golang源码阅读"],"content":"mapdelete和mapclear func mapdelete(t *maptype, h *hmap, key unsafe.Pointer) { if raceenabled \u0026\u0026 h != nil { callerpc := getcallerpc() pc := funcPC(mapdelete) racewritepc(unsafe.Pointer(h), callerpc, pc) raceReadObjectPC(t.key, key, callerpc, pc) } if msanenabled \u0026\u0026 h != nil { msanread(key, t.key.size) } if h == nil || h.count == 0 { if t.hashMightPanic() { t.hasher(key, 0) // see issue 23734 } return } if h.flags\u0026hashWriting != 0 { throw(\"concurrent map writes\") } hash := t.hasher(key, uintptr(h.hash0)) // Set hashWriting after calling t.hasher, since t.hasher may panic, // in which case we have not actually done a write (delete). h.flags ^= hashWriting bucket := hash \u0026 bucketMask(h.B) if h.growing() { growWork(t, h, bucket) } b := (*bmap)(add(h.buckets, bucket*uintptr(t.bucketsize))) bOrig := b top := tophash(hash) search: for ; b != nil; b = b.overflow(t) { for i := uintptr(0); i \u003c bucketCnt; i++ { if b.tophash[i] != top { if b.tophash[i] == emptyRest { break search } continue } k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) k2 := k if t.indirectkey() { k2 = *((*unsafe.Pointer)(k2)) } if !t.key.equal(key, k2) { continue } // Only clear key if there are pointers in it. if t.indirectkey() { *(*unsafe.Pointer)(k) = nil } else if t.key.ptrdata != 0 { memclrHasPointers(k, t.key.size) } e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize)) if t.indirectelem() { *(*unsafe.Pointer)(e) = nil } else if t.elem.ptrdata != 0 { memclrHasPointers(e, t.elem.size) } else { memclrNoHeapPointers(e, t.elem.size) } b.tophash[i] = emptyOne // If the bucket now ends in a bunch of emptyOne states, // change those to emptyRest states. // It would be nice to make this a separate function, but // for loops are not currently inlineable. if i == bucketCnt-1 { if b.overflow(t) != nil \u0026\u0026 b.overflow(t).tophash[0] != emptyRest { goto notLast } } else { if b.tophash[i+1] != emptyRest { goto notLast } } for { b.tophash[i] = emptyRest if i == 0 { if b == bOrig { break // beginning of initial bucket, we're done. } // Find previous bucket, continue at its last entry. c := b for b = bOrig; b.overflow(t) != c; b = b.overflow(t) { } i = bucketCnt - 1 } else { i-- } if b.tophash[i] != emptyOne { break } } notLast: h.count-- break search } } if h.flags\u0026hashWriting == 0 { throw(\"concurrent map writes\") } h.flags \u0026^= hashWriting } // mapclear deletes all keys from a map. func mapclear(t *maptype, h *hmap) { if raceenabled \u0026\u0026 h != nil { callerpc := getcallerpc() pc := funcPC(mapclear) racewritepc(unsafe.Pointer(h), callerpc, pc) } if h == nil || h.count == 0 { return } if h.flags\u0026hashWriting != 0 { throw(\"concurrent map writes\") } h.flags ^= hashWriting h.flags \u0026^= sameSizeGrow h.oldbuckets = nil h.nevacuate = 0 h.noverflow = 0 h.count = 0 // Keep the mapextra allocation but clear any extra information. if h.extra != nil { *h.extra = mapextra{} } // makeBucketArray clears the memory pointed to by h.buckets // and recovers any overflow buckets by generating them // as if h.buckets was newly alloced. _, nextOverflow := makeBucketArray(t, h.B, h.buckets) if nextOverflow != nil { // If overflow buckets are created then h.extra // will have been allocated during initial bucket creation. h.extra.nextOverflow = nextOverflow } if h.flags\u0026hashWriting == 0 { throw(\"concurrent map writes\") } h.flags \u0026^= hashWriting } mapdelete函数顾名思义，从map里删除一个key。如果理解了mapaccess的代码，就会发现这个函数大部分的逻辑都如出一辙，无非就是 mapaccess找到key在map中的位置。 清空key和elem，如果是指针，就设为nil，如果不是指针，就清空相应大小的内存，然后把tophash对应的元素设为emptyOne。 这里有一个delete自己的优化，占用了一个独立的循环。在执行完清空操作之后，进行如下的检测： 如果被删除的key占用的是这个bucket的最后一个键值对空间，那么就看有没有overflow，有的话，overflow是否为空，如果overflow不为空，那就直接跳到结束删除的收尾工作。 如果被删除的key不是这个bucket的最后一个键值对空间，那么就直接检查下一个tophash是不是emptyRest，如果不是，那么就直接跳到结束删除的收尾工作。 如果上面两种情况没有满足，那么进入一个回溯的循环。先把这个当前位置的tophash设置为emptyRest，表示后面都是空。然后再看一下，key的位置i是不是0。如果是，在当前bucket所属的overflow bucket链中，找到上一个bucket，并把i设为7,指到最后一个键值对空间。如果不是，那么直接i向前走1,指向前一个键值对空间。然后检查这个键值对是不是emptyOne，如果不是，就直接break，进入删除收尾的工作。如果是，继续这个循环，在下一次循环开","date":"2020-05-26","objectID":"/go-map/:9:0","tags":["golang","runtime","map","源码阅读"],"title":"Golang Map源码阅读笔记","uri":"/go-map/"},{"categories":["golang源码阅读"],"content":"map的扩容 func hashGrow(t *maptype, h *hmap) { // If we've hit the load factor, get bigger. // Otherwise, there are too many overflow buckets, // so keep the same number of buckets and \"grow\" laterally. bigger := uint8(1) if !overLoadFactor(h.count+1, h.B) { bigger = 0 h.flags |= sameSizeGrow } oldbuckets := h.buckets newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil) flags := h.flags \u0026^ (iterator | oldIterator) if h.flags\u0026iterator != 0 { flags |= oldIterator } // commit the grow (atomic wrt gc) h.B += bigger h.flags = flags h.oldbuckets = oldbuckets h.buckets = newbuckets h.nevacuate = 0 h.noverflow = 0 if h.extra != nil \u0026\u0026 h.extra.overflow != nil { // Promote current overflow buckets to the old generation. if h.extra.oldoverflow != nil { throw(\"oldoverflow is not nil\") } h.extra.oldoverflow = h.extra.overflow h.extra.overflow = nil } if nextOverflow != nil { if h.extra == nil { h.extra = new(mapextra) } h.extra.nextOverflow = nextOverflow } // the actual copying of the hash table data is done incrementally // by growWork() and evacuate(). } func growWork(t *maptype, h *hmap, bucket uintptr) { // make sure we evacuate the oldbucket corresponding // to the bucket we're about to use evacuate(t, h, bucket\u0026h.oldbucketmask()) // evacuate one more oldbucket to make progress on growing if h.growing() { evacuate(t, h, h.nevacuate) } } type evacDst struct { b *bmap // current destination bucket i int // key/elem index into b k unsafe.Pointer // pointer to current key storage e unsafe.Pointer // pointer to current elem storage } func evacuate(t *maptype, h *hmap, oldbucket uintptr) { b := (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize))) newbit := h.noldbuckets() if !evacuated(b) { // TODO: reuse overflow buckets instead of using new ones, if there // is no iterator using the old buckets. (If !oldIterator.) // xy contains the x and y (low and high) evacuation destinations. var xy [2]evacDst x := \u0026xy[0] x.b = (*bmap)(add(h.buckets, oldbucket*uintptr(t.bucketsize))) x.k = add(unsafe.Pointer(x.b), dataOffset) x.e = add(x.k, bucketCnt*uintptr(t.keysize)) if !h.sameSizeGrow() { // Only calculate y pointers if we're growing bigger. // Otherwise GC can see bad pointers. y := \u0026xy[1] y.b = (*bmap)(add(h.buckets, (oldbucket+newbit)*uintptr(t.bucketsize))) y.k = add(unsafe.Pointer(y.b), dataOffset) y.e = add(y.k, bucketCnt*uintptr(t.keysize)) } for ; b != nil; b = b.overflow(t) { k := add(unsafe.Pointer(b), dataOffset) e := add(k, bucketCnt*uintptr(t.keysize)) for i := 0; i \u003c bucketCnt; i, k, e = i+1, add(k, uintptr(t.keysize)), add(e, uintptr(t.elemsize)) { top := b.tophash[i] if isEmpty(top) { b.tophash[i] = evacuatedEmpty continue } if top \u003c minTopHash { throw(\"bad map state\") } k2 := k if t.indirectkey() { k2 = *((*unsafe.Pointer)(k2)) } var useY uint8 if !h.sameSizeGrow() { // Compute hash to make our evacuation decision (whether we need // to send this key/elem to bucket x or bucket y). hash := t.hasher(k2, uintptr(h.hash0)) if h.flags\u0026iterator != 0 \u0026\u0026 !t.reflexivekey() \u0026\u0026 !t.key.equal(k2, k2) { // If key != key (NaNs), then the hash could be (and probably // will be) entirely different from the old hash. Moreover, // it isn't reproducible. Reproducibility is required in the // presence of iterators, as our evacuation decision must // match whatever decision the iterator made. // Fortunately, we have the freedom to send these keys either // way. Also, tophash is meaningless for these kinds of keys. // We let the low bit of tophash drive the evacuation decision. // We recompute a new random tophash for the next level so // these keys will get evenly distributed across all buckets // after multiple grows. useY = top \u0026 1 top = tophash(hash) } else { if hash\u0026newbit != 0 { useY = 1 } } } if evacuatedX+1 != evacuatedY || evacuatedX^1 != evacuatedY { throw(\"bad evacuatedN\") } b.tophash[i] = evacuatedX + useY // evacuatedX + 1 == evacuatedY dst := \u0026xy[useY] // evacuation destination if dst.i == bucketCnt { dst.b = h.newoverflow(","date":"2020-05-26","objectID":"/go-map/:10:0","tags":["golang","runtime","map","源码阅读"],"title":"Golang Map源码阅读笔记","uri":"/go-map/"},{"categories":["golang源码阅读"],"content":"普通工具函数 // bucketShift returns 1\u003c\u003cb, optimized for code generation. func bucketShift(b uint8) uintptr { // Masking the shift amount allows overflow checks to be elided. return uintptr(1) \u003c\u003c (b \u0026 (sys.PtrSize*8 - 1)) } // bucketMask returns 1\u003c\u003cb - 1, optimized for code generation. func bucketMask(b uint8) uintptr { return bucketShift(b) - 1 } // tophash calculates the tophash value for hash. func tophash(hash uintptr) uint8 { top := uint8(hash \u003e\u003e (sys.PtrSize*8 - 8)) if top \u003c minTopHash { top += minTopHash } return top } func evacuated(b *bmap) bool { h := b.tophash[0] return h \u003e emptyOne \u0026\u0026 h \u003c minTopHash } func (b *bmap) overflow(t *maptype) *bmap { return *(**bmap)(add(unsafe.Pointer(b), uintptr(t.bucketsize)-sys.PtrSize)) } func (b *bmap) setoverflow(t *maptype, ovf *bmap) { *(**bmap)(add(unsafe.Pointer(b), uintptr(t.bucketsize)-sys.PtrSize)) = ovf } func (b *bmap) keys() unsafe.Pointer { return add(unsafe.Pointer(b), dataOffset) } // overLoadFactor reports whether count items placed in 1\u003c\u003cB buckets is over loadFactor. func overLoadFactor(count int, B uint8) bool { return count \u003e bucketCnt \u0026\u0026 uintptr(count) \u003e loadFactorNum*(bucketShift(B)/loadFactorDen) } // tooManyOverflowBuckets reports whether noverflow buckets is too many for a map with 1\u003c\u003cB buckets. // Note that most of these overflow buckets must be in sparse use; // if use was dense, then we'd have already triggered regular map growth. func tooManyOverflowBuckets(noverflow uint16, B uint8) bool { // If the threshold is too low, we do extraneous work. // If the threshold is too high, maps that grow and shrink can hold on to lots of unused memory. // \"too many\" means (approximately) as many overflow buckets as regular buckets. // See incrnoverflow for more details. if B \u003e 15 { B = 15 } // The compiler doesn't see here that B \u003c 16; mask B to generate shorter shift code. return noverflow \u003e= uint16(1)\u003c\u003c(B\u002615) } // growing reports whether h is growing. The growth may be to the same size or bigger. func (h *hmap) growing() bool { return h.oldbuckets != nil } // sameSizeGrow reports whether the current growth is to a map of the same size. func (h *hmap) sameSizeGrow() bool { return h.flags\u0026sameSizeGrow != 0 } // noldbuckets calculates the number of buckets prior to the current map growth. func (h *hmap) noldbuckets() uintptr { oldB := h.B if !h.sameSizeGrow() { oldB-- } return bucketShift(oldB) } // oldbucketmask provides a mask that can be applied to calculate n % noldbuckets(). func (h *hmap) oldbucketmask() uintptr { return h.noldbuckets() - 1 } func bucketEvacuated(t *maptype, h *hmap, bucket uintptr) bool { b := (*bmap)(add(h.oldbuckets, bucket*uintptr(t.bucketsize))) return evacuated(b) } 函数bucketShift接收一个参数是hmap.B，计算得到分配bucket的数量，里面的b \u0026 (sys.PtrSize*8 - 1)，只是为了省略掉溢出的检测，在64位的平台上，最多把uintptr(1)左移63位，其他位宽同理，这个位宽就是通过sys.PtrSize获得的。 函数bucketMask在bucketShift基础上，通过-1操作，获得一个111111111...的掩码。这个掩码后面在定位bucket的时候被用来保证偏移量不会溢出。 函数tophash接收一个参数hash，应该是一个平台位宽长度的哈希值，例如amd64平台上就是一个64bit的哈希值。取这个哈希值的最高8bit作为key的tophash（索引），注意这里要预留minTopHash给迁移状态位。 函数evacuated 通过读取tophash[0]的值，判断一个bucket是否已经在扩容过程中被迁移了。 方法overflow 根据*maptype的bucketsize来获得当前bucket所包含的指向overflow bucket的指针。因为操作内容就是指针本身，所以通过偏移量计算之后得到的是指针的指针。 方法setoverflow 同上，这个是相对应的setter方法。 方法keys 通过在b的地址上+dataOffset来获取存放key的起始地址。dataOffset是在常量定义里预先计算好的固定偏移量，其实可以认为就是tophash占用的内存大小。 ","date":"2020-05-26","objectID":"/go-map/:11:0","tags":["golang","runtime","map","源码阅读"],"title":"Golang Map源码阅读笔记","uri":"/go-map/"},{"categories":["golang源码阅读"],"content":"把hiter放在最后 // A hash iteration structure. // If you modify hiter, also change cmd/compile/internal/gc/reflect.go to indicate // the layout of this structure. type hiter struct { key unsafe.Pointer // Must be in first position. Write nil to indicate iteration end (see cmd/internal/gc/range.go). elem unsafe.Pointer // Must be in second position (see cmd/internal/gc/range.go). t *maptype h *hmap buckets unsafe.Pointer // bucket ptr at hash_iter initialization time bptr *bmap // current bucket overflow *[]*bmap // keeps overflow buckets of hmap.buckets alive oldoverflow *[]*bmap // keeps overflow buckets of hmap.oldbuckets alive startBucket uintptr // bucket iteration started at offset uint8 // intra-bucket offset to start from during iteration (should be big enough to hold bucketCnt-1) wrapped bool // already wrapped around from end of bucket array to beginning B uint8 i uint8 bucket uintptr checkBucket uintptr } // mapiterinit initializes the hiter struct used for ranging over maps. // The hiter struct pointed to by 'it' is allocated on the stack // by the compilers order pass or on the heap by reflect_mapiterinit. // Both need to have zeroed hiter since the struct contains pointers. func mapiterinit(t *maptype, h *hmap, it *hiter) { if raceenabled \u0026\u0026 h != nil { callerpc := getcallerpc() racereadpc(unsafe.Pointer(h), callerpc, funcPC(mapiterinit)) } if h == nil || h.count == 0 { return } if unsafe.Sizeof(hiter{})/sys.PtrSize != 12 { throw(\"hash_iter size incorrect\") // see cmd/compile/internal/gc/reflect.go } it.t = t it.h = h // grab snapshot of bucket state it.B = h.B it.buckets = h.buckets if t.bucket.ptrdata == 0 { // Allocate the current slice and remember pointers to both current and old. // This preserves all relevant overflow buckets alive even if // the table grows and/or overflow buckets are added to the table // while we are iterating. h.createOverflow() it.overflow = h.extra.overflow it.oldoverflow = h.extra.oldoverflow } // decide where to start r := uintptr(fastrand()) if h.B \u003e 31-bucketCntBits { r += uintptr(fastrand()) \u003c\u003c 31 } it.startBucket = r \u0026 bucketMask(h.B) it.offset = uint8(r \u003e\u003e h.B \u0026 (bucketCnt - 1)) // iterator state it.bucket = it.startBucket // Remember we have an iterator. // Can run concurrently with another mapiterinit(). if old := h.flags; old\u0026(iterator|oldIterator) != iterator|oldIterator { atomic.Or8(\u0026h.flags, iterator|oldIterator) } mapiternext(it) } func mapiternext(it *hiter) { h := it.h if raceenabled { callerpc := getcallerpc() racereadpc(unsafe.Pointer(h), callerpc, funcPC(mapiternext)) } if h.flags\u0026hashWriting != 0 { throw(\"concurrent map iteration and map write\") } t := it.t bucket := it.bucket b := it.bptr i := it.i checkBucket := it.checkBucket next: if b == nil { if bucket == it.startBucket \u0026\u0026 it.wrapped { // end of iteration it.key = nil it.elem = nil return } if h.growing() \u0026\u0026 it.B == h.B { // Iterator was started in the middle of a grow, and the grow isn't done yet. // If the bucket we're looking at hasn't been filled in yet (i.e. the old // bucket hasn't been evacuated) then we need to iterate through the old // bucket and only return the ones that will be migrated to this bucket. oldbucket := bucket \u0026 it.h.oldbucketmask() b = (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize))) if !evacuated(b) { checkBucket = bucket } else { b = (*bmap)(add(it.buckets, bucket*uintptr(t.bucketsize))) checkBucket = noCheck } } else { b = (*bmap)(add(it.buckets, bucket*uintptr(t.bucketsize))) checkBucket = noCheck } bucket++ if bucket == bucketShift(it.B) { bucket = 0 it.wrapped = true } i = 0 } for ; i \u003c bucketCnt; i++ { offi := (i + it.offset) \u0026 (bucketCnt - 1) if isEmpty(b.tophash[offi]) || b.tophash[offi] == evacuatedEmpty { // TODO: emptyRest is hard to use here, as we start iterating // in the middle of a bucket. It's feasible, just tricky. continue } k := add(unsafe.Pointer(b), dataOffset+uintptr(offi)*uintptr(t.keysize)) if t.indirectkey() { k = *((*unsafe.Pointer)(k)) } e := add(unsa","date":"2020-05-26","objectID":"/go-map/:12:0","tags":["golang","runtime","map","源码阅读"],"title":"Golang Map源码阅读笔记","uri":"/go-map/"}]